{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c29f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import config\n",
    "import inflect\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import torch\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from minicons import scorer\n",
    "from minicons import utils as mu\n",
    "from minicons import openai as mo\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "inflector = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3671cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/kanishka/<OPENAIKEY>\"\n",
    "mo.register_api_key(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02d30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AANN:\n",
    "    article: str\n",
    "    adjective: str\n",
    "    numeral: str\n",
    "    noun: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.string = re.sub(\n",
    "            r\"\\s{2,}\",\n",
    "            \" \",\n",
    "            f\"{self.article} {self.adjective} {self.numeral} {self.noun}\",\n",
    "        ).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bf3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_aann(string, pattern):\n",
    "    tokens = string.split()\n",
    "    adj_span = re.search(config.ADJ_PATTERN, pattern).group(0)\n",
    "    num_span = re.search(config.NUM_PATTERN, pattern).group(0)\n",
    "\n",
    "    adjs_idx = mu.find_pattern(adj_span.split(), pattern.split())\n",
    "    nums_idx = mu.find_pattern(num_span.split(), pattern.split())\n",
    "\n",
    "    parsed = AANN(\n",
    "        tokens[0],\n",
    "        \" \".join(tokens[adjs_idx[0] : adjs_idx[1]]),\n",
    "        \" \".join(tokens[nums_idx[0] : nums_idx[1]]),\n",
    "        \" \".join(tokens[nums_idx[1] :]),\n",
    "    )\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1145ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instance(aann):\n",
    "    return parse_aann(aann[\"construction\"], aann[\"pattern\"])\n",
    "\n",
    "\n",
    "def construction_pieces(sentence, construction):\n",
    "    left, right = mu.character_span(sentence, construction)\n",
    "    return sentence[:left], sentence[left:right], sentence[right:]\n",
    "\n",
    "\n",
    "def reconstruct(left, middle, right, left_only=False):\n",
    "    if left_only:\n",
    "        concat_pieces = [left, middle]\n",
    "    else:\n",
    "        concat_pieces = [left, middle, right]\n",
    "    string = \" \".join(concat_pieces).strip()\n",
    "    return re.sub(r\" {2,}\", \" \", string)\n",
    "\n",
    "\n",
    "def left_only(sentence, construction):\n",
    "    left, right = mu.character_span(sentence, construction)\n",
    "    return sentence[:left].strip(), sentence[left:right]\n",
    "\n",
    "\n",
    "def default_ann(aann):\n",
    "    return AANN(\"\", aann.numeral, aann.adjective, aann.noun)\n",
    "\n",
    "\n",
    "def corrupt_order(aann):\n",
    "    article = inflector.a(aann.numeral.split(\" \")[0]).split(\" \")[0]\n",
    "    return AANN(article, aann.numeral, aann.adjective, aann.noun)\n",
    "\n",
    "\n",
    "def corrupt_article(aann):\n",
    "    return AANN(\"\", aann.adjective, aann.numeral, aann.noun)\n",
    "\n",
    "\n",
    "def corrupt_modifier(aann):\n",
    "    article = inflector.a(aann.numeral.split(\" \")[0]).split(\" \")[0]\n",
    "    return AANN(article, \"\", aann.numeral, aann.noun)\n",
    "\n",
    "\n",
    "def corrupt_numeral(aann):\n",
    "    return AANN(aann.article, aann.adjective, \"\", aann.noun)\n",
    "\n",
    "\n",
    "def corrupt_noun_num(aann):\n",
    "    noun = inflector.singular_noun(aann.noun.split(\" \")[-1])\n",
    "    return AANN(aann.article, aann.adjective, aann.numeral, noun)\n",
    "\n",
    "\n",
    "# extractors implemented as aann corruptors.\n",
    "def non_article_region(aann):\n",
    "    return AANN(\"\", aann.adjective, aann.numeral, aann.noun)\n",
    "\n",
    "\n",
    "def numeral_noun_region(aann):\n",
    "    return AANN(\"\", \"\", aann.numeral, aann.noun)\n",
    "\n",
    "\n",
    "def just_noun_region(aann):\n",
    "    return AANN(\"\", \"\", \"\", aann.noun)\n",
    "\n",
    "\n",
    "def left_context(sentence, construction, token_span):\n",
    "    candidate_spans = [it.span() for it in re.finditer(token_span, sentence)]\n",
    "    if len(candidate_spans) == 1:\n",
    "        selected_span = candidate_spans[0]\n",
    "    else:\n",
    "        try:\n",
    "            construction_span = re.search(construction, sentence).span()\n",
    "        except:\n",
    "            construction_span = re.search(\n",
    "                re.escape(construction), sentence\n",
    "            ).span()\n",
    "        selected_span = [\n",
    "            cs\n",
    "            for cs in candidate_spans\n",
    "            if utils.belongingness(cs, construction_span)\n",
    "        ][0]\n",
    "\n",
    "    if sentence == construction == token_span:\n",
    "        return \"\", sentence\n",
    "    else:\n",
    "        return (\n",
    "            sentence[: selected_span[0] - 1],\n",
    "            sentence[selected_span[0] : selected_span[1]],\n",
    "        )\n",
    "\n",
    "\n",
    "def segment(instances, extractor, corruptor=None, only_construction=False):\n",
    "    full_length, prefixes, continuations = [], [], []\n",
    "    for instance in instances:\n",
    "        parsed = parse_instance(instance)\n",
    "        if corruptor is not None:\n",
    "            parsed = corruptor(parsed)\n",
    "            left, construction, right = construction_pieces(\n",
    "                instance[\"sentence\"], instance[\"construction\"]\n",
    "            )\n",
    "            sentence = reconstruct(left, parsed.string, right)\n",
    "            construction = parsed.string\n",
    "        else:\n",
    "            sentence = instance[\"sentence\"]\n",
    "            construction = instance[\"construction\"]\n",
    "\n",
    "        predicted_item = extractor(parsed)\n",
    "\n",
    "        if only_construction:\n",
    "            sentence = construction\n",
    "\n",
    "        p, c = left_context(sentence, construction, predicted_item.string)\n",
    "        prefixes.append(p)\n",
    "        continuations.append(c)\n",
    "        full_length.append((p + \" \" + c).strip())\n",
    "    return full_length, prefixes, continuations\n",
    "\n",
    "EXTRACTORS = {\n",
    "    'construction': lambda x: x,\n",
    "    'non_article_region': non_article_region,\n",
    "    'numeral_noun_region': numeral_noun_region,\n",
    "    'just_noun_region': just_noun_region,\n",
    "}\n",
    "\n",
    "def compute_scores(model, data, batch_size=32, modifier=None, extractors=None):\n",
    "    \n",
    "    scores = defaultdict(list)\n",
    "\n",
    "    batches = mu.get_batch(data, batch_size)    \n",
    "\n",
    "    for batch in tqdm(batches):\n",
    "        sequences, prefixes, continuations = segment(batch, lambda x: x, modifier)\n",
    "        \n",
    "        lm = mo.OpenAIQuery(model, sequences)\n",
    "        lm.query()\n",
    "        \n",
    "        for extractor in extractors:\n",
    "            seq, pref, extracted_continuations = segment(batch, EXTRACTORS[extractor], modifier)\n",
    "#             print(extractor, seq)\n",
    "            \n",
    "            scores[extractor].extend(lm.conditional_score(extracted_continuations))\n",
    "            \n",
    "    scores = dict(scores)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f790dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = utils.read_csv_dict(f\"../data/mahowald/aanns_good.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78cd6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTORS_AND_MODIFIERS = {\n",
    "    \"default_ann\": ('non_article_region', default_ann),\n",
    "    \"order_swap\": ('non_article_region', corrupt_order),\n",
    "    \"no_article\": ('non_article_region', corrupt_article),\n",
    "    \"no_modifier\": ('numeral_noun_region', corrupt_modifier),\n",
    "    \"no_numeral\": ('just_noun_region', corrupt_numeral),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7852abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'idx': [aann['idx'] for aann in good]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2639b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:33,  2.16it/s]\n",
      "203it [01:40,  2.02it/s]\n",
      "203it [01:49,  1.85it/s]\n",
      "203it [01:34,  2.14it/s]\n",
      "203it [01:47,  1.88it/s]\n",
      "203it [01:36,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "s = compute_scores('text-davinci-003', good, 64, lambda x: x, list(EXTRACTORS.keys()))\n",
    "\n",
    "for e, scores in s.items():\n",
    "    results[f\"{e}_score\"] = scores\n",
    "    \n",
    "for em, (extractor, modifier) in EXTRACTORS_AND_MODIFIERS.items():\n",
    "    extractor_list = ['construction', extractor]\n",
    "    s2 = compute_scores('text-davinci-003', good, 64, modifier,  extractor_list)\n",
    "    results[f\"{em}_corruption_score\"] = s2['construction']\n",
    "    results[f\"{em}_region_score\"] = s2[extractor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f036557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 12960, 'construction_score': 12960, 'non_article_region_score': 12960, 'numeral_noun_region_score': 12960, 'just_noun_region_score': 12960, 'default_ann_construction_score': 12960, 'default_ann_region_score': 12960, 'order_swap_construction_score': 12960, 'order_swap_region_score': 12960, 'no_article_construction_score': 12960, 'no_article_region_score': 12960, 'no_modifier_construction_score': 12960, 'no_modifier_region_score': 12960, 'no_numeral_construction_score': 12960, 'no_numeral_region_score': 12960}\n"
     ]
    }
   ],
   "source": [
    "print({k: len(v) for k, v in results.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0a766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prefix = f\"../data/results/mahowald/text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992cbab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e17816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = results_df.rename(columns={\"construction\": \"construction_score\", \n",
    "#                            \"non_article_region\": \"non_article_region_score\", \n",
    "#                            \"numeral_noun_region\": \"numeral_noun_region_score\",\n",
    "#                            \"just_noun_region\": \"just_noun_region_score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067a9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"{results_prefix}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
