{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0ca55b-6e14-4a49-91ad-09bd4dc535b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import spacy\n",
    "import unicodedata\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from minicons.utils import find_pattern\n",
    "from spacy.lang.en import English\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import config\n",
    "import minicons.utils as mu\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d06f344e-338a-4c39-8679-6ba90ec08d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/km55359/.conda/envs/kmisra/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nlp = English()\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405db466-7a2c-4603-9bd3-5843935c1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regexes\n",
    "ADVANCED_REGEX = r'\\b(DT)(?:(?:\\s(RB))*\\s(JJ|JJR|JJS)(?:\\s(CC))*)+(\\s(CD|JJ|JJR|JJS|CD\\sCD)(?:\\s(TO|CC)\\s(CD))*)(\\s(NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'\n",
    "ULTRA_REGEX = r'\\b(DT)(?:(?:\\s(RB))*\\s(JJ|JJR|JJS)(?:\\s(CC))*)+(\\s(CD|JJ|JJR|JJS|NN|CD\\sCD)(?:\\s(TO|CC)\\s(CD))*)(\\s(NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'\n",
    "AANN_REGEX = r\"\\b(DT)(?:(?:\\s(RB))*\\s(JJ|JJR|JJS)(?:\\s(CC))*)+(\\s(CD)(?:\\s(TO|CC)\\s(CD))*)(\\s(NNS|NNPS))+\"\n",
    "\n",
    "cats = ['DT', 'ADJ', 'NUMERAL', 'NOUN', \"ADV\"]\n",
    "non_numerals = ['few', 'dozen', 'couple', 'several', 'many', 'more']\n",
    "\n",
    "pos2cat = {\n",
    "    'DT': 'DT',\n",
    "    'JJ': 'ADJ',\n",
    "    'JJR': 'ADJ',\n",
    "    'JJS': 'ADJ',\n",
    "    'CD': 'NUMERAL',\n",
    "    'NNS': 'NOUN',\n",
    "    'NNPS': 'NOUN',\n",
    "    'NN': 'NOUN',\n",
    "    'IN': 'NOUN',\n",
    "    'RB': 'ADV',\n",
    "    'CC': 'CC',\n",
    "    'TO': 'TO'\n",
    "}\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"TODO: make read all\"\"\"\n",
    "    return [i.strip() for i in open(path, encoding=\"utf-8\").readlines()]\n",
    "\n",
    "def detect_aann_advanced(sequence):\n",
    "    return re.search(ADVANCED_REGEX, sequence)\n",
    "\n",
    "def detect_aann_basic(sequence):\n",
    "    return re.search(AANN_REGEX, sequence)\n",
    "\n",
    "def detect_aann_ultra(sequence):\n",
    "    return re.search(ULTRA_REGEX, sequence)\n",
    "\n",
    "def tokenize(string):\n",
    "    return [t.text for t in tokenizer(string)]\n",
    "\n",
    "def aann_meta(token_seq, const_pattern):\n",
    "    form_elements = {\n",
    "        'DT': [],\n",
    "        'ADJ': [],\n",
    "        'NUMERAL': [],\n",
    "        'NOUN': [],\n",
    "        'ADV': []\n",
    "    }\n",
    "    for token, element in zip(token_seq, const_pattern.split()):\n",
    "        category = pos2cat[element]\n",
    "        if category in cats:\n",
    "            form_elements[category].append(token)\n",
    "\n",
    "    fe_strings = {k:\" & \".join(v) for k,v in form_elements.items()}\n",
    "\n",
    "    # return form_elements\n",
    "    return fe_strings\n",
    "\n",
    "def is_ultra(seq):\n",
    "    searched_advanced = detect_aann_advanced(seq)\n",
    "    searched_basic = detect_aann_basic(seq)\n",
    "    searched_ultra = detect_aann_ultra(seq)\n",
    "    return searched_ultra and not searched_advanced\n",
    "\n",
    "def store_aann_spans(pos_seq):\n",
    "    aanns = []\n",
    "    for i, seq in enumerate(pos_seq):\n",
    "        searched_advanced = detect_aann_advanced(seq)\n",
    "        searched_basic = detect_aann_basic(seq)\n",
    "        searched_ultra = detect_aann_ultra(seq)\n",
    "        if searched_basic:\n",
    "            aanns.append((i, seq, searched_basic.span()))\n",
    "        elif searched_advanced:\n",
    "            aanns.append((i, seq, searched_advanced.span()))\n",
    "        elif searched_ultra:\n",
    "            aanns.append((i, seq, searched_ultra.span()))\n",
    "    return aanns\n",
    "\n",
    "def store_aanns(sents, pos_seq, corpus=None):\n",
    "    full_aann_data = []\n",
    "    \n",
    "    # get spans\n",
    "    aanns = store_aann_spans(pos_seq)\n",
    "\n",
    "    # given spans, extract sentences and infor relevant for parsing.\n",
    "    for entry in aanns:\n",
    "        idx, pos_seq, span = entry\n",
    "        construction_pattern = pos_seq[span[0] : span[1]]\n",
    "        construction_pattern_span = find_pattern(\n",
    "            construction_pattern.split(), pos_seq.split()\n",
    "        )\n",
    "\n",
    "        tokens = tokenize(sents[idx])\n",
    "        if tokens == []:\n",
    "            pass\n",
    "        else:\n",
    "            extracted_token_seq = tokens[\n",
    "                construction_pattern_span[0] : construction_pattern_span[1]\n",
    "            ]\n",
    "            if extracted_token_seq[0].lower().startswith(\"-a\"):\n",
    "                extracted_token_seq[0] = (\n",
    "                    extracted_token_seq[0].replace(\"-a\", \"a\").replace(\"-A\", \"A\")\n",
    "                )\n",
    "            # if indefinite_articles:\n",
    "            #     condition = extracted_token_seq[0].lower() in [\"a\", \"an\", \"-a\", \"another\"]\n",
    "            # else:\n",
    "            #     condition = True\n",
    "            # if condition:\n",
    "            construction_form = \" \".join(extracted_token_seq)\n",
    "\n",
    "            construction_elements = aann_meta(\n",
    "                extracted_token_seq, construction_pattern\n",
    "            )\n",
    "            construction_elements[\"sentence\"] = sents[idx]\n",
    "            construction_elements[\"sentence_idx\"] = idx\n",
    "            construction_elements[\"pattern\"] = construction_pattern\n",
    "            construction_elements[\"source\"] = corpus\n",
    "            construction_elements[\"construction\"] = construction_form\n",
    "\n",
    "            if is_ultra(construction_pattern):\n",
    "                if construction_elements['NOUN'].split(\" & \")[0] in non_numerals:\n",
    "                    full_aann_data.append(construction_elements)\n",
    "            else:\n",
    "                full_aann_data.append(construction_elements)\n",
    "\n",
    "    return full_aann_data\n",
    "\n",
    "def indefinite_article_aanns(aann_list):\n",
    "    indef_article_aanns = []\n",
    "    for entry in aann_list:\n",
    "        if entry['construction'].split()[0].lower() in [\"a\", \"an\", \"-a\", \"another\"]:\n",
    "            indef_article_aanns.append(entry)\n",
    "    return indef_article_aanns\n",
    "\n",
    "# 5179 + 37\n",
    "\n",
    "def verify_and_edit(entry):\n",
    "    new_entry = entry.copy()\n",
    "    if new_entry['NUMERAL'] == '':\n",
    "        adjs = new_entry['ADJ'].split(\" & \")\n",
    "        final_adj = adjs[-1]\n",
    "        nouns = new_entry['NOUN'].split(\" & \")\n",
    "        first_noun = nouns[0]\n",
    "        # first check noun:\n",
    "        if first_noun in non_numerals and len(nouns[1:]) >= 1:\n",
    "            decomposed_construction = new_entry['construction'].split(\" \")\n",
    "            idx_in_decomp = [i for i, w in enumerate(decomposed_construction) if w == first_noun][-1]\n",
    "            new_entry['NOUN'] = \" & \".join(nouns[1:])\n",
    "            new_entry['NUMERAL'] = first_noun\n",
    "\n",
    "            # replace value in position of numeral-adj in pattern to 'CD' so that the aann is parsed.\n",
    "            new_pattern = new_entry['pattern'].split(\" \")\n",
    "            new_pattern[idx_in_decomp] = \"CD\"\n",
    "            new_entry['pattern'] = \" \".join(new_pattern)\n",
    "            \n",
    "        if final_adj in non_numerals and len(adjs[:-1]) >= 1: # gotcha\n",
    "            decomposed_construction = new_entry['construction'].split(\" \")\n",
    "            idx_in_decomp = [i for i, w in enumerate(decomposed_construction) if w == final_adj][-1]\n",
    "            new_entry['ADJ'] = \" & \".join(adjs[:-1])\n",
    "            new_entry['NUMERAL'] = final_adj\n",
    "            \n",
    "            # replace value in position of numeral-adj in pattern to 'CD' so that the aann is parsed.\n",
    "            new_pattern = new_entry['pattern'].split(\" \")\n",
    "            new_pattern[idx_in_decomp] = \"CD\"\n",
    "            new_entry['pattern'] = \" \".join(new_pattern)\n",
    "    return new_entry\n",
    "\n",
    "def prune_sentence(entry):\n",
    "    new_entry = entry.copy()\n",
    "    sentences = sent_tokenize(new_entry['sentence'])\n",
    "    construction = new_entry['construction']\n",
    "    \n",
    "    # if there is more than one sentence in the input\n",
    "    if len(sentences) > 1:\n",
    "        # check which of them has the construction\n",
    "        if construction in new_entry['sentence']:\n",
    "            for s in sentences:\n",
    "                if construction in s:\n",
    "                    final_sentence = s\n",
    "                    break\n",
    "        else:\n",
    "            for s in sentences:\n",
    "                reconstructed = ' '.join(tokenize(s))\n",
    "                if construction in reconstructed:\n",
    "                    final_sentence = s\n",
    "                    break\n",
    "        # make change\n",
    "        new_entry['sentence'] = final_sentence\n",
    "        \n",
    "    return new_entry\n",
    "\n",
    "def find_sentence(target, source):\n",
    "    idx = []\n",
    "    for i, s in enumerate(source):\n",
    "        if unicodedata.normalize(\"NFKD\", s) == target:\n",
    "            idx.append(i)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3622d5d5-0de8-45d2-a8f7-7c775da6f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sents and postags\n",
    "sent_dir = \"/home/km55359/rawdata/babylm_data/babylm_100M/sents/\"\n",
    "# sent_dir = \"/Users/kanishka/rawdata/babylm-sents-and-postags/\"\n",
    "sents = utils.read_file(f\"{sent_dir}/babylm_sents.txt\")\n",
    "postags = utils.read_file(f\"{sent_dir}/postags.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe0ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# find lines that contain the aanns we missed:\n",
    "\n",
    "MISSED = ['a record 9 times',\n",
    " 'a record 21 months',\n",
    " 'a record eight times',\n",
    " 'an extra 200 sit-ups',\n",
    " 'a full  ninety minutes',\n",
    " 'a good like six months',\n",
    " 'a great two-and-a-half dates',\n",
    " 'a club record 26 league games',\n",
    " 'an estimated 100,000 climbers',\n",
    " 'an extra hundred and... two pounds',\n",
    " 'an amazing a hundred and thirty points',\n",
    " 'an estimated 438,000 species of plants',\n",
    " 'an additional twenty five million pounds',\n",
    " 'an additional twenty five million pounds',\n",
    " 'a further sixty-eight policemen, which has',\n",
    " 'an additional twenty five million pounds is',\n",
    " 'an estimated 90,750 hectares (224,000 acres',\n",
    " 'a combined 73 goals for Celta, Albacete, Alavés',\n",
    " 'a general 1-2\" of snow. Some places saw as much as',\n",
    " 'a career-high 266 yards and two scores as Northern Illinois',\n",
    " 'a busy, busy few weeks for you, has']\n",
    "\n",
    "print(len(MISSED))\n",
    "\n",
    "missed_sents = []\n",
    "missed_sents_idx = []\n",
    "\n",
    "for i, s in enumerate(sents):\n",
    "    for m in MISSED:\n",
    "        if m in s:\n",
    "            missed_sents.append(s)\n",
    "            missed_sents_idx.append(i)\n",
    "\n",
    "\n",
    "missed_postags = [postags[i] for i in missed_sents_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77dd871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missed_postags), len(missed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae2b1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT VBN NNS IN NNS',\n",
       " 'DT JJ IN JJS CD NNS',\n",
       " 'DT JJ NNS IN NNS RB',\n",
       " 'DT JJ NNS TO NNS IN NNS NNS',\n",
       " 'DT JJ NNS IN NNS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_postag_patterns = [\n",
    "    \"DT NN NN CD NN NNS\",\n",
    "    \"DT NN HYPH JJ CD NNS\",\n",
    "    \"DT NN CD NNS\",\n",
    "    \"DT JJ CD CD CD NNS\",\n",
    "    \"DT VBN CD NNS\",\n",
    "    \"DT JJ CD HYPH CD NNS\",\n",
    "    \"DT JJ UH CD NNS\",\n",
    "    \"DT JJ CD CC HYPH CD NNS\",\n",
    "    \"DT JJ , JJ JJ NNS\",\n",
    "    \"DT RB RB CD NNS\"\n",
    "]\n",
    "\n",
    "\n",
    "exceptions = [\"DT JJ DT CD CC CD NNS\", \"DT JJ CD HYPH CC HYPH DT HYPH NN NNS\", \"DT JJ NNP CD NNS\"]\n",
    "\n",
    "reviewer = '''DT VBN NNS IN NNS\n",
    "DT JJ IN JJS CD NNS\n",
    "DT JJ NNS IN NNS RB\n",
    "DT JJ NNS TO NNS IN NNS NNS\n",
    "DT JJ NNS IN NNS'''.split(\"\\n\")\n",
    "\n",
    "reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe01150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 214955/11632617 [00:00<00:10, 1079141.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11632617/11632617 [00:08<00:00, 1305234.75it/s]\n"
     ]
    }
   ],
   "source": [
    "missed_counts = defaultdict(int)\n",
    "for p in tqdm(postags):\n",
    "    for pp in missed_postag_patterns:\n",
    "        if pp in p:\n",
    "            missed_counts[pp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa2c9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11632617 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11632617/11632617 [00:04<00:00, 2331163.38it/s]\n"
     ]
    }
   ],
   "source": [
    "reviewer_counts = defaultdict(int)\n",
    "for p in tqdm(postags):\n",
    "    for pp in reviewer:\n",
    "        if pp in p:\n",
    "            reviewer_counts[pp] += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4926fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'DT JJ NNS IN NNS': 1565,\n",
       "             'DT JJ NNS IN NNS RB': 48,\n",
       "             'DT VBN NNS IN NNS': 60})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewer_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7b0321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11632617it [00:06, 1678527.66it/s]\n"
     ]
    }
   ],
   "source": [
    "reviewer_missed_pattern_counts = defaultdict(int)\n",
    "reviewer_missed_pattern_spans = defaultdict(list)\n",
    "for i, (s, p) in enumerate(tqdm(zip(sents, postags))):\n",
    "    for pattern in reviewer:\n",
    "        if pattern in p:\n",
    "            # tokenize sentence\n",
    "            sent_tokens = tokenize(s)\n",
    "            searched = re.search(fr'{pattern}', p)\n",
    "            span = searched.span()\n",
    "            construction_pattern = p[span[0] : span[1]]\n",
    "            construction_pattern_span = find_pattern(\n",
    "                construction_pattern.split(), p.split()\n",
    "            )\n",
    "            if sent_tokens == []:\n",
    "                print(sent_tokens, p)\n",
    "            else:\n",
    "                try:\n",
    "                    sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                    if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                        reviewer_missed_pattern_counts[pattern] += 1\n",
    "                        reviewer_missed_pattern_spans[pattern].append((i, s, p, sent_span))\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e731fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11632617it [00:14, 794304.67it/s]\n"
     ]
    }
   ],
   "source": [
    "ohno = []\n",
    "missed_pattern_counts = defaultdict(int)\n",
    "missed_pattern_spans = defaultdict(list)\n",
    "for i, (s, p) in enumerate(tqdm(zip(sents, postags))):\n",
    "    for pattern in missed_postag_patterns + exceptions:\n",
    "        if pattern in p:\n",
    "            # tokenize sentence\n",
    "            sent_tokens = tokenize(s)\n",
    "            searched = re.search(fr'{pattern}', p)\n",
    "            span = searched.span()\n",
    "            construction_pattern = p[span[0] : span[1]]\n",
    "            construction_pattern_span = find_pattern(\n",
    "                construction_pattern.split(), p.split()\n",
    "            )\n",
    "            if sent_tokens == []:\n",
    "                print(sent_tokens, p)\n",
    "            else:\n",
    "                try:\n",
    "                    sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                    if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                        missed_pattern_counts[pattern] += 1\n",
    "                        missed_pattern_spans[pattern].append((i, s, p, sent_span))\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb78a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a further erm sixteen hectares\n",
      "a s er two slates\n",
      "a good like six months\n",
      "a marvelous like two nights\n"
     ]
    }
   ],
   "source": [
    "# set([\" \".join(x[-1]) for x in missed_pattern_spans[\"DT NN HYPH JJ CD NNS\"]])\n",
    "def pattern_instances(pattern):\n",
    "   unique = set([\" \".join(x[-1]) for x in dict(missed_pattern_spans)[pattern]])\n",
    "   for x in unique:\n",
    "    print(x)\n",
    "\n",
    "pattern_instances(\"DT JJ UH CD NNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c66ecb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'DT NN CD NNS': 744,\n",
       "             'DT NN HYPH JJ CD NNS': 54,\n",
       "             'DT VBN CD NNS': 99,\n",
       "             'DT JJ CD HYPH CD NNS': 6,\n",
       "             'DT JJ UH CD NNS': 5,\n",
       "             'DT NN NN CD NN NNS': 2,\n",
       "             'DT JJ , JJ JJ NNS': 6,\n",
       "             'DT JJ CD CD CD NNS': 11,\n",
       "             'DT JJ NNP CD NNS': 4,\n",
       "             'DT JJ DT CD CC CD NNS': 1,\n",
       "             'DT RB RB CD NNS': 1,\n",
       "             'DT JJ CD HYPH CC HYPH DT HYPH NN NNS': 2,\n",
       "             'DT JJ CD CC HYPH CD NNS': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_pattern_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78bbc8f-dce2-4f5a-b98d-9a77c892514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_aann_data = store_aanns(sents, postags, \"babylm_sents\")\n",
    "full_aann_data_indef = indefinite_article_aanns(full_aann_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f05cff0f-3614-4d97-ba3e-2bae920461d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34407, 5231)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_aann_data), len(full_aann_data_indef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34dcfc2b-b4de-4cf9-b0a3-6e23e5dfc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_aann_data_corpuswise = []\n",
    "\n",
    "for file in glob.glob(\"/home/km55359/rawdata/babylm_data/postags_100M/*.train\"):\n",
    "    corpus = re.split(r\"(/|.train)\", file)[-3]\n",
    "    corpus_postags = read_file(file)\n",
    "    corpus_sents = read_file(f\"/home/km55359/rawdata/babylm_data/babylm_100M/{corpus}.train\")\n",
    "\n",
    "    full_aann_data_corpuswise.extend(store_aanns(corpus_sents, corpus_postags, corpus))\n",
    "\n",
    "full_aann_data_corpuswise_indef = indefinite_article_aanns(full_aann_data_corpuswise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46e72abf-0336-485f-883b-43a60048b89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33719, 5186)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_aann_data_corpuswise), len(full_aann_data_corpuswise_indef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "524c802e-6550-410d-be0e-5b33efa1a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5186"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "prune sents in source\n",
    "for those that do not exist in sent_aanns, add\n",
    "\n",
    "then do numeral stuff.\n",
    "separate out numeral --> save\n",
    "for non numeral, verify and edit\n",
    "if after numeral is empty, ignore, else add to non_numeral_final.\n",
    "'''\n",
    "full_aann_data_corpuswise_indef_pruned = []\n",
    "for entry in full_aann_data_corpuswise_indef:\n",
    "    pruned = prune_sentence(entry)\n",
    "    # idx = find_sentence(pruned['sentence'], sents)\n",
    "    # pruned['sentence_idx'] = idx\n",
    "    full_aann_data_corpuswise_indef_pruned.append(pruned)\n",
    "\n",
    "len(full_aann_data_corpuswise_indef_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b844b01-9915-4d96-93e2-877e5d32de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get diff ids\n",
    "corpuswise_constructions = [c['construction'] for c in full_aann_data_corpuswise_indef_pruned]\n",
    "sentencewise_constructions = [c['construction'] for c in full_aann_data_indef]\n",
    "\n",
    "diff_ids = [i for i, x in enumerate(corpuswise_constructions) if x not in sentencewise_constructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd11199b-a045-4d8f-b7cc-74ef6077cfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2282"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_aann_data_indef_final = []\n",
    "for entry in full_aann_data_indef:\n",
    "    edited = verify_and_edit(entry)\n",
    "    if edited['NUMERAL'] != '':\n",
    "        full_aann_data_indef_final.append(edited)\n",
    "\n",
    "len(full_aann_data_indef_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31338ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2301"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actually_detected = utils.read_csv_dict(\"../data/babylm-aanns/aanns_indef_all.csv\")\n",
    "len(actually_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92e0e4c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CURRENT_REGEX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_idx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m p \u001b[38;5;241m=\u001b[39m postags[idx]\n\u001b[0;32m---> 10\u001b[0m searched \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[43mCURRENT_REGEX\u001b[49m, p)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m searched:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CURRENT_REGEX' is not defined"
     ]
    }
   ],
   "source": [
    "# for x in all_og_patterns:\n",
    "#     searched = re.search(CURRENT_REGEX, x)\n",
    "#     if not searched:\n",
    "#         print(x)\n",
    "not_found_in_og = []\n",
    "not_found_in_og_pattern = set()\n",
    "for entry in actually_detected:\n",
    "    idx = int(entry['sentence_idx'])\n",
    "    p = postags[idx]\n",
    "    searched = re.search(CURRENT_REGEX, p)\n",
    "    if searched:\n",
    "        pass\n",
    "    else:\n",
    "        not_found_in_og_pattern.add(entry['pattern'])\n",
    "        not_found_in_og.append(entry)\n",
    "# actually_detected[1020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fdecbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'An estimated 10,000 people',\n",
       " 'An estimated 140 people',\n",
       " 'An estimated 150 radio stations',\n",
       " 'An estimated 343,000 people',\n",
       " 'a combined 52 league appearances',\n",
       " 'a distinctive two story veranda',\n",
       " 'a few 37 \\xa0 mm weapons',\n",
       " 'a further 20–24 \\xa0 cm',\n",
       " 'a further 7 \\xa0 km',\n",
       " 'a great many barrows',\n",
       " 'a great many crumples',\n",
       " 'a great many fellows',\n",
       " 'a great many secrets',\n",
       " 'a half million votes',\n",
       " 'a hulking 261 \\xa0 pounds',\n",
       " 'a reported 150,000 prisoners',\n",
       " 'a reported 6,000 apartments',\n",
       " 'a total 111 floors',\n",
       " 'an annual 5$000 réis'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actually_detected[0], full_aann_data_indef_final[0]\n",
    "final_unique = set([x['construction'] for x in full_aann_data_indef_final])\n",
    "actually_unique = set([x['construction'] for x in actually_detected])\n",
    "\n",
    "actually_unique - final_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4b90d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_REGEX = r'\\b(DT)(?:(?:\\s(RB))*\\s(JJ|JJR|JJS)(?:\\s(CC))*)+(\\s(CD|JJ|JJR|JJS|NN|CD\\sCD)(?:\\s(TO|CC)\\s(CD))*)(\\s(NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'\n",
    "# PERMISSIVE_REGEX = \"\"\n",
    "# NEW_CANDIDATE = {\n",
    "#     \"05/24\": r'\\b(DT)(\\s(HYPH|,))?(?:(?:\\s(RB)+)*\\s(NN CC NN|NN HYPH JJ|VBN|JJ|JJR|JJS)(\\s(HYPH|,))?(?:\\s(CC))*)+(\\s(HYPH|,))?(\\s(CD|JJ|JJR|JJS|NN|CD\\sCD)(?:\\s(TO|CC)\\s(CD))*)(\\s(HYPH|,))?(\\s(NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+',\n",
    "    \n",
    "# }\n",
    "\n",
    "# CURRENT_REGEX = r'\\bDT\\s(((HYPH|,)\\s))?((((RB|CC)\\s)+)?((JJ|JJR|JJS|VBN|((NN CC NN |NN HYPH )+(JJ|JJR|JJS|VBN)))((\\s(HYPH|,))?)\\s))+(((HYPH|,)\\s))?(((NN|CC)\\s)+)?((CD)(\\s(TO|CC|(HYPH|,))(\\s(HYPH|,))?)?\\s)+(((HYPH|,)\\s))?(JJR\\s)?((NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+' TODO: KEEP AROUND IF UH IS NOT NEEDED\n",
    "\n",
    "CURRENT_REGEX = r'\\bDT\\s(((HYPH|,)\\s))?((((RB|CC)\\s)+)?((JJ|JJR|JJS|VBN|((NN CC NN |NN HYPH )+(JJ|JJR|JJS|VBN)))((\\s(HYPH|,))?)\\s))+(((RB)\\s)+)?(((HYPH|,)\\s))?((UH)\\s)?(((NN|CC)\\s)+)?((CD)(\\s(TO|CC|(HYPH|,))(\\s(HYPH|,))?)?\\s)+(((HYPH|,)\\s))?(JJR\\s)?((NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'\n",
    "\n",
    "DEP_PARSE_REGEX = r'\\bDT\\s(((HYPH|,)\\s))?((((RB|CC|IN)\\s)+)?((JJ|NN|JJR|JJS|VBN|((NN CC NN |NN HYPH )+(JJ|JJR|JJS|VBN)))((\\s(HYPH|,))?)\\s))+(((RB)\\s)+)?(((HYPH|,)\\s))?((UH)\\s)?(((NN|CC)\\s)+)?((CD)(\\s(TO|CC|(HYPH|,))(\\s(HYPH|,))?)?\\s)+(((HYPH|,)\\s))?(JJR\\s)?((NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'\n",
    "\n",
    "CURRENT_WITH_DT_REGEX = r'\\bDT\\s(((HYPH|,)\\s))?((((RB|CC|IN)\\s)+)?((JJ|JJR|JJS|VBN|((NN CC NN |NN HYPH )+(JJ|JJR|JJS|VBN)))((\\s(HYPH|,))?)\\s))+(((RB)\\s)+)?(((HYPH|,)\\s))?((UH)\\s)?(((NN|CC)\\s)+)?((CD)(\\s(TO|CC|(HYPH|,))(\\s(HYPH|,))?)?\\s)+(((HYPH|,)\\s))?(JJR\\s)?(DT\\s)?((NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a2f272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spans(pattern_repository):\n",
    "    pattern_spans = defaultdict(list)\n",
    "    for i, (s, p) in enumerate(tqdm(zip(sents, postags))):\n",
    "        for pattern in pattern_repository:\n",
    "            searched = re.search(fr'{pattern}', p)\n",
    "            # if re.search(fr'{pattern}', p):\n",
    "            if searched:\n",
    "                # tokenize sentence\n",
    "                sent_tokens = tokenize(s)\n",
    "                span = searched.span()\n",
    "                construction_pattern = p[span[0] : span[1]]\n",
    "                construction_pattern_span = find_pattern(\n",
    "                    construction_pattern.split(), p.split()\n",
    "                )\n",
    "                if sent_tokens == []:\n",
    "                    print(sent_tokens, p)\n",
    "                else:\n",
    "                    try:\n",
    "                        sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                        if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                            # missed_pattern_counts[pattern] += 1\n",
    "                            pattern_spans[pattern].append((i, sent_span))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "    pattern_counts = {k: len(v) for k,v in pattern_spans.items()}\n",
    "    pattern_spans = dict(pattern_spans)\n",
    "    return pattern_spans, pattern_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8483ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UH , UH , PRP VBP PRP VBP RB VBN VBN NN IN DT JJ JJ NNS , CC EX VBZ DT NN TO VB VB PRP$ NNS NNS .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags[2481]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c427bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yeah, well, I know I've not 'ad bath for a good few seasons, but there's no need to 'urt my feelin's.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[2481]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e9c9ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 21), match='DT JJ CC JJ JJ CD NNS'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for entry in actually_detected:\n",
    "#     if entry['NUMERAL'] == \"few\":\n",
    "#         print(entry['pattern'])\n",
    "\n",
    "# for i, s in enumerate(sents):\n",
    "#     if \"a good few marriages\" in s:\n",
    "#         print(i, s, postags[i])\n",
    "\n",
    "# pattern = \"DT JJ CC JJ JJ CD NNS\"\n",
    "# searched = re.search(CURRENT_REGEX, pattern)\n",
    "# searched\n",
    "\n",
    "CURRENT_REGEX_FEW = r'\\bDT\\s(((HYPH|,)\\s))?((((RB|CC)\\s)+)?((JJ|JJR|JJS|VBN|((NN CC NN |NN HYPH )+(JJ|JJR|JJS|VBN)))((\\s(HYPH|,))?)\\s))+(((RB)\\s)+)?(((HYPH|,)\\s))?((UH)\\s)?(((NN|CC)\\s)+)?((CD)(\\s(TO|CC|(HYPH|,))(\\s(HYPH|,))?)?\\s)+(((HYPH|,)\\s))?(JJR\\s)?((NNS|NNPS|(NN\\sNNS)|((NN|NNS) IN NNS)))+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc35b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11632617it [00:48, 239500.44it/s]\n"
     ]
    }
   ],
   "source": [
    "repo = [OLD_REGEX, CURRENT_REGEX, DEP_PARSE_REGEX, CURRENT_WITH_DT_REGEX]\n",
    "regex_spans, regex_counts = find_spans(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "335c8784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT JJ , JJ JJ NNS\n",
      "a few , few little things\n",
      "a little , few little notes\n",
      "a private , coeducational liberal arts\n",
      "a great , many round ones\n",
      "a busy , busy few weeks\n",
      "a few , long swift strokes\n"
     ]
    }
   ],
   "source": [
    "unmissed = []\n",
    "still_missed = []\n",
    "still_missed_patterns = []\n",
    "for ms, mp in zip(missed_sents, missed_postags):\n",
    "    if re.search(CURRENT_REGEX, mp):\n",
    "        unmissed.append((ms, mp))\n",
    "    elif re.search(CURRENT_WITH_DT_REGEX, mp):\n",
    "        unmissed.append((ms, mp))\n",
    "    elif re.search(DEP_PARSE_REGEX, mp):\n",
    "        unmissed.append((ms, mp))\n",
    "    else:\n",
    "        still_missed.append((ms, mp))\n",
    "        for mpp in missed_postag_patterns:\n",
    "            if mpp in mp:\n",
    "                still_missed_patterns.append(mpp)\n",
    "\n",
    "for x in set(still_missed_patterns):\n",
    "    print(x)\n",
    "    pattern_instances(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25adcd70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'still_missed_patterns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mset\u001b[39m(\u001b[43mstill_missed_patterns\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'still_missed_patterns' is not defined"
     ]
    }
   ],
   "source": [
    "set(still_missed_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29b50b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unmissed), len(still_missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8ab610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM SAMPLE FROM 100M\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random_idx = random.sample(range(0, len(sents)), 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be81d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "babylm_100M_subset_10M = [sents[i] for i in random_idx]\n",
    "babylm_100M_subset_10M_postags = [postags[i] for i in random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba1405fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Well, I don't know.\", 'UH , PRP VBP RB VB .')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babylm_100M_subset_10M[0], babylm_100M_subset_10M_postags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6481a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permissive_regex = r'\\b(a|an|another)\\b .{0,100} \\b(two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred|thousand|million|billion|several|few|couple|dozen|tens|dozens|hundreds|thousands|millions|billions|[0-9]+)\\b.{0,100}\\b\\w+s\\b'\n",
    "\n",
    "\n",
    "permissed = []\n",
    "for i, s, p in zip(random_idx, babylm_100M_subset_10M, babylm_100M_subset_10M_postags):\n",
    "    searched = re.search(permissive_regex, s)\n",
    "    try:\n",
    "        init, final = searched.span()\n",
    "        permissed.append((i, s, p, s[init:final]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# permissed_sampled = permissed[:1000]\n",
    "permissed_sampled = permissed[1001:2001]\n",
    "# permissed_sampled = random.sample(permissed, 1000)\n",
    "\n",
    "len(permissed_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70634808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/permissed_sampled.csv\", \"w\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"sentence\", \"postags\", \"span\"])\n",
    "#     for i, s, p, sp in permissed_sampled:\n",
    "#         writer.writerow([s, p, sp])\n",
    "\n",
    "# with open(\"../data/permissed_sampled_test.csv\", \"w\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"sentence\", \"postags\", \"span\"])\n",
    "#     for i, s, p, sp in permissed_sampled:\n",
    "#         writer.writerow([s, p, sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "249c1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permissed[0]\n",
    "og_aann_idx = [int(x['sentence_idx']) for x in actually_detected]\n",
    "idx2span = {int(x['sentence_idx']): x['construction'] for x in actually_detected}\n",
    "\n",
    "detected_by_og = []\n",
    "detected_by_current = []\n",
    "detected_by_current_with_dep_parse = []\n",
    "detected_by_current_with_dt = []\n",
    "\n",
    "for i, s, p, sp in permissed_sampled:\n",
    "    if i in og_aann_idx:\n",
    "        detected_by_og.append((i, s, p, idx2span[i]))\n",
    "\n",
    "    current = re.search(CURRENT_REGEX, p)  \n",
    "    dep_parse = re.search(DEP_PARSE_REGEX, p)\n",
    "    current_with_dt = re.search(CURRENT_WITH_DT_REGEX, p)  \n",
    "    if current:\n",
    "        sent_tokens = tokenize(s)\n",
    "        span = current.span()\n",
    "        construction_pattern = p[span[0] : span[1]]\n",
    "        construction_pattern_span = find_pattern(\n",
    "            construction_pattern.split(), p.split()\n",
    "        )\n",
    "        if sent_tokens == []:\n",
    "            print(sent_tokens, p)\n",
    "        else:\n",
    "            try:\n",
    "                sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                    detected_by_current.append((i, s, p, sent_span))\n",
    "            except:\n",
    "                pass\n",
    "    if dep_parse:\n",
    "        sent_tokens = tokenize(s)\n",
    "        span = dep_parse.span()\n",
    "        construction_pattern = p[span[0] : span[1]]\n",
    "        construction_pattern_span = find_pattern(\n",
    "            construction_pattern.split(), p.split()\n",
    "        )\n",
    "        if sent_tokens == []:\n",
    "            print(sent_tokens, p)\n",
    "        else:\n",
    "            try:\n",
    "                sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                    detected_by_current_with_dep_parse.append((i, s, p, sent_span))\n",
    "            except:\n",
    "                pass\n",
    "    if current_with_dt:\n",
    "        sent_tokens = tokenize(s)\n",
    "        span = current_with_dt.span()\n",
    "        construction_pattern = p[span[0] : span[1]]\n",
    "        construction_pattern_span = find_pattern(\n",
    "            construction_pattern.split(), p.split()\n",
    "        )\n",
    "        if sent_tokens == []:\n",
    "            print(sent_tokens, p)\n",
    "        else:\n",
    "            try:\n",
    "                sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                    detected_by_current_with_dt.append((i, s, p, sent_span))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5e91f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25, 54, 25)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_by_og), len(detected_by_current), len(detected_by_current_with_dep_parse), len(detected_by_current_with_dt)\n",
    "# len(permissed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "20c6111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a good few marriages\n",
      "a fucking few minutes\n",
      "a good few thousands\n",
      "an extra few pints\n",
      "a great many more people\n"
     ]
    }
   ],
   "source": [
    "# for x in detected_by_current:\n",
    "#     if x not in detected_by_og:\n",
    "#         print(x)\n",
    "og_detected_spans = [x[-1] for x in detected_by_og]\n",
    "current_detected_spans = [\" \".join(x[-1]) for x in detected_by_current]\n",
    "for x in og_detected_spans:\n",
    "    if x not in current_detected_spans:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8231c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permissed_sampled_annotated = utils.read_csv_dict(\"../data/permissed_sampled_annotated.csv\")\n",
    "permissed_sampled_annotated = utils.read_csv_dict(\"../data/permissed_sampled_annotated_test1_1k.csv\")\n",
    "\n",
    "with open(\"../data/permissed_sampled_annotated_test1_1k_predictions.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"sentence\", \"pos\", \"span\", \"length\", \"aann\", \"og_detected\", \"current_detected\", \"dep_parse_detected\", \"current_with_dt_detected\"])\n",
    "    for entry in permissed_sampled_annotated:\n",
    "        s = entry[\"sentence\"]\n",
    "        p = entry[\"pos\"]\n",
    "        # og_detected = int(entry[\"span\"] in idx2span.values())\n",
    "        og = re.search(ULTRA_REGEX, p)\n",
    "        current = re.search(CURRENT_REGEX, p)  \n",
    "        dep_parse = re.search(DEP_PARSE_REGEX, p)\n",
    "        current_with_dt = re.search(CURRENT_WITH_DT_REGEX, p)\n",
    "        og_detected = 0\n",
    "        current_detected = 0\n",
    "        dep_parse_detected = 0\n",
    "        current_with_dt_detected = 0\n",
    "        if og:\n",
    "            sent_tokens = tokenize(s)\n",
    "            span = og.span()\n",
    "            construction_pattern = p[span[0] : span[1]]\n",
    "            construction_pattern_span = find_pattern(\n",
    "                construction_pattern.split(), p.split()\n",
    "            )\n",
    "            if sent_tokens == []:\n",
    "                print(sent_tokens, p)\n",
    "            else:\n",
    "                try:\n",
    "                    sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                    if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                        # detected_by_current.append((i, s, p, sent_span))\n",
    "                        og_detected = 1\n",
    "                    else:\n",
    "                        og_detected = 0\n",
    "                except:\n",
    "                    pass\n",
    "        if current:\n",
    "            sent_tokens = tokenize(s)\n",
    "            span = current.span()\n",
    "            construction_pattern = p[span[0] : span[1]]\n",
    "            construction_pattern_span = find_pattern(\n",
    "                construction_pattern.split(), p.split()\n",
    "            )\n",
    "            if sent_tokens == []:\n",
    "                print(sent_tokens, p)\n",
    "            else:\n",
    "                try:\n",
    "                    sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                    if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                        # detected_by_current.append((i, s, p, sent_span))\n",
    "                        current_detected = 1\n",
    "                    else:\n",
    "                        current_detected = 0\n",
    "                except:\n",
    "                    pass\n",
    "        if dep_parse:\n",
    "            sent_tokens = tokenize(s)\n",
    "            span = dep_parse.span()\n",
    "            construction_pattern = p[span[0] : span[1]]\n",
    "            construction_pattern_span = find_pattern(\n",
    "                construction_pattern.split(), p.split()\n",
    "            )\n",
    "            if sent_tokens == []:\n",
    "                print(sent_tokens, p)\n",
    "            else:\n",
    "                try:\n",
    "                    sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                    if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                        # detected_by_current_with_dep_parse.append((i, s, p, sent_span))\n",
    "                        dep_parse_detected = 1\n",
    "                    else:\n",
    "                        dep_parse_detected = 0\n",
    "                except:\n",
    "                    pass\n",
    "        if current_with_dt:\n",
    "            sent_tokens = tokenize(s)\n",
    "            span = current_with_dt.span()\n",
    "            construction_pattern = p[span[0] : span[1]]\n",
    "            construction_pattern_span = find_pattern(\n",
    "                construction_pattern.split(), p.split()\n",
    "            )\n",
    "            if sent_tokens == []:\n",
    "                print(sent_tokens, p)\n",
    "            else:\n",
    "                try:\n",
    "                    sent_span = sent_tokens[construction_pattern_span[0] : construction_pattern_span[1]]\n",
    "                    if sent_span[0] in (\"a\", \"an\", \"another\"):\n",
    "                        # detected_by_current_with_dt.append((i, s, p, sent_span))\n",
    "                        current_with_dt_detected = 1\n",
    "                    else:\n",
    "                        current_with_dt_detected = 0\n",
    "                except:\n",
    "                    pass\n",
    "        writer.writerow([entry[\"sentence\"], entry[\"pos\"], entry[\"span\"], entry[\"length\"], entry[\"aann\"], og_detected, current_detected, dep_parse_detected, current_with_dt_detected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "633c8e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a record 1.5 million pre',\n",
       " 'a further 46,750 tons',\n",
       " 'a champion 4 years',\n",
       " 'a flood here about ten years',\n",
       " 'a season - high four stops',\n",
       " 'a season - high two pass deflections',\n",
       " 'a cell 4 dots',\n",
       " 'a very thrillingly impressive eight points',\n",
       " 'a town twenty miles',\n",
       " 'a fun two months',\n",
       " 'an orchard approximately 1.5 miles',\n",
       " 'a common ancestor approximately 40 million years',\n",
       " 'a man and two horses',\n",
       " 'a reliable 72 hours',\n",
       " 'a long and two shorts',\n",
       " 'a couple million songs',\n",
       " 'a small village roughly 15 kilometres',\n",
       " 'an additional 26 states',\n",
       " 'a ring worth nine lakhs',\n",
       " 'a game 300 runs',\n",
       " 'a successful three years',\n",
       " 'an extra two thousand years',\n",
       " 'a house , four carriages',\n",
       " 'a phenomenon 100 years',\n",
       " 'a gentle 20 miles',\n",
       " 'a community place , about five or six years',\n",
       " 'an acute accent , 2 letters',\n",
       " 'a copperhead skin two hours',\n",
       " 'a small market town 14 miles',\n",
       " 'a further 16 languages',\n",
       " 'a solo violin , two violins',\n",
       " 'an hour and thirty minutes',\n",
       " 'a spot twenty yards',\n",
       " 'a day , 365 days',\n",
       " 'a book held about fourteen inches',\n",
       " 'a school - record 46 tackles',\n",
       " 'an estimated 182 persons',\n",
       " 'a few hundred dollars',\n",
       " 'a few hundred copies',\n",
       " 'an i-- times 6 times',\n",
       " 'a precautionary measure , 12 states',\n",
       " 'an alert , five conditions',\n",
       " 'a later date , 278 votes',\n",
       " 'a pilot and six - passengers',\n",
       " 'a patch about twenty - two yards',\n",
       " 'a further erm sixteen hectares',\n",
       " 'a month , eleven months',\n",
       " 'a bodyguard eight hundred men',\n",
       " 'a season eight years',\n",
       " 'a year , plus four rounds',\n",
       " 'a close encounter approximately 1 billion years',\n",
       " 'a further three years',\n",
       " 'a few million years',\n",
       " 'a good six , seven diamonds',\n",
       " 'a full three inches',\n",
       " 'a pleasant rest and two restaurants',\n",
       " 'a purist , two parts',\n",
       " 'a season - high 19 points',\n",
       " 'a few hundred yards',\n",
       " 'an additional three awards',\n",
       " 'another offer , four times',\n",
       " 'a harbour 60 miles',\n",
       " 'a small covered area , about forty seats',\n",
       " 'a gun club three years']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(x[-1]) for x in detected_by_current_with_dep_parse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "229a056b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a few more IQ points\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more inches\n",
      "a few more steps\n",
      "a few more times\n",
      "a few more strokes\n",
      "a few more steps\n",
      "a few more minutes\n",
      "a few more recordings\n",
      "a few more miles\n",
      "a few more festival appearances\n",
      "a few more minutes\n",
      "a few more years\n",
      "a few more days\n",
      "a few more days\n",
      "a few more houses\n",
      "a great many more Mice\n",
      "a few more arrows\n",
      "a few more logs\n",
      "a few more things\n",
      "a few more crumbs\n",
      "a few more people\n",
      "a few more instructions\n",
      "a few more days\n",
      "a few more dams\n",
      "a few more appearances\n",
      "a few more ways\n",
      "a few more things\n",
      "a few more examples\n",
      "a few more things\n",
      "a great many more things\n",
      "a few more questions\n",
      "a few more crumbs\n",
      "a few more miles\n",
      "a few more years\n",
      "a few more runs\n",
      "a few more calls\n",
      "a few more minutes\n",
      "a few more outings\n",
      "a few more expostulations\n",
      "a few more inheritances\n",
      "A few more words\n",
      "a few more questions\n",
      "a few more minutes\n",
      "a few more notes\n",
      "a few more nuggets\n",
      "a few more days\n",
      "a few more notes\n",
      "a few more hysterics\n",
      "A few more minutes\n",
      "a few more notes\n",
      "A few more minutes\n",
      "a few more jokes\n",
      "A few more settlers\n",
      "a great many more deaths\n",
      "a few more chances\n",
      "a few more tricks\n",
      "A few more wretches\n",
      "a few more words\n",
      "a few more minutes\n",
      "A few more days\n",
      "a few more IQ points\n",
      "a few more deals\n",
      "a few more cents\n",
      "A few more summers\n",
      "a few more shows\n",
      "a few more hours\n",
      "a few more credit cards\n",
      "a few more things\n",
      "a few more days\n",
      "a few more minutes\n",
      "a few more bowls\n",
      "a few more minutes\n",
      "a few more fits\n",
      "a few more minutes\n",
      "a few more words\n",
      "a few more things\n",
      "a few more questions\n",
      "a few more men\n",
      "A few more trees\n",
      "a few more women\n",
      "a few more weeks\n",
      "a few more Liechtensteiners\n",
      "a few more years\n",
      "A few more experiences\n",
      "a few more things\n",
      "a few more pictures\n",
      "a few more iterations\n",
      "a few more boards\n",
      "a few more singles\n",
      "a few more songs\n",
      "a few more moments\n",
      "a few more days\n",
      "a few more times\n",
      "a few more compositions\n",
      "a few more days\n",
      "a few more steps\n",
      "a few more things\n",
      "a few more visits\n",
      "a few more ideas\n",
      "A few more words\n",
      "a few more notes\n",
      "a few more seconds\n",
      "a few more minutes\n",
      "a few more houses\n",
      "a few more years\n",
      "a few more recipes\n",
      "a few more questions\n",
      "a few more minutes\n",
      "a few more editing tools\n",
      "a good many more mice\n",
      "a few more days\n",
      "a few more blows\n",
      "A few more words\n",
      "a few more days\n",
      "a few more words\n",
      "a few more minutes\n",
      "a few more dancers\n",
      "a few more shots\n",
      "a few more gravestones\n",
      "a few more words\n",
      "A great many more factors\n",
      "a few more seconds\n",
      "a few more gravestones\n",
      "a few more words\n",
      "a few more marks\n",
      "a few more years\n",
      "a few more notations\n",
      "A few more revolutions\n",
      "a few more men\n",
      "a few more minutes\n",
      "a few more days\n",
      "a few more demonstrations\n",
      "A few more wing strokes\n",
      "a few more years\n",
      "a few more jumps\n",
      "a few more inches\n",
      "a few more days\n",
      "a few more things\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more questions\n",
      "a few more days\n",
      "a few more days\n",
      "a few more days\n",
      "a few more letters\n",
      "a few more examples\n",
      "a few more slides\n",
      "a few more people\n",
      "a few more leads\n",
      "a few more women\n",
      "a few more encounters\n",
      "a few more months\n",
      "a few more hints\n",
      "A few more words\n",
      "a great many more variables\n",
      "A few more words\n",
      "a few more patients\n",
      "a few more pieces\n",
      "A few more seconds\n",
      "a few more pounds\n",
      "a few more words\n",
      "a few more spots\n",
      "a few more highlights\n",
      "a few more years\n",
      "A few more facts\n",
      "a few more ways\n",
      "a few more voters\n",
      "a few more stars\n",
      "a few more equations\n",
      "a few more factories\n",
      "a few more frills\n",
      "a few more theories\n",
      "a few more minutes\n",
      "a few more things\n",
      "a few more products\n",
      "a few more minutes\n",
      "a few more noughts\n",
      "a few more minutes\n",
      "a few more questions\n",
      "a few more books\n",
      "a few more minutes\n",
      "A few more seconds\n",
      "a few more flipflops\n",
      "a few more hours\n",
      "a few more minutes\n",
      "a few more things\n",
      "a few more things\n",
      "a few more people\n",
      "A few more questions\n",
      "a few more coppers\n",
      "a few more minutes\n",
      "a few more decades\n",
      "a few more games\n",
      "a few more days\n",
      "a few more movies\n",
      "a few more days\n",
      "a few more days\n",
      "a few more rooms\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more seats\n",
      "a few more years\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more songs\n",
      "a few more people\n",
      "a few more options\n",
      "a few more minutes\n",
      "a few more responsibilities\n",
      "a few more days\n",
      "a few more days\n",
      "a few more hits\n",
      "a few more years\n",
      "a few more people\n",
      "a few more years\n",
      "a few more years\n",
      "A few more Germans\n",
      "a few more seconds\n",
      "a few more words\n",
      "a few more things\n",
      "a few more days\n",
      "a few more lighters\n",
      "a few more states\n",
      "a few more tests\n",
      "a few more books\n",
      "a few more days\n",
      "a few more minutes\n",
      "a little more lentils\n",
      "a few more details\n",
      "a few more details\n",
      "a few more hours\n",
      "a few more years\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more acts\n",
      "a few more stulls\n",
      "a few more pages\n",
      "a few more curses\n",
      "a few more trees\n",
      "a few more days\n",
      "a few more neutrons\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more techniques\n",
      "a few more topics\n",
      "a few more minutes\n",
      "a few more seconds\n",
      "a few more months\n",
      "a few more matches\n",
      "a few more songs\n",
      "a few more yards\n",
      "a few more matters\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more times\n",
      "a few more dollars\n",
      "A few more feet\n",
      "a few more minutes\n",
      "A few more answers\n",
      "A few more steps\n",
      "a few more men\n",
      "a few more days\n",
      "a few more years\n",
      "a few more days\n",
      "a few more questions\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more photos\n",
      "a few more knaves\n",
      "a few more gunshots\n",
      "a few more submenu items\n",
      "a few more voices\n",
      "a few more words\n",
      "a few more minutes\n",
      "a few more miracles\n",
      "a few more miracles\n",
      "a few more panes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more screws\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more steps\n",
      "a few more minutes\n",
      "a great many more people\n",
      "a few more assemblies\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "A few more minutes\n",
      "a few more lessons\n",
      "a few more days\n",
      "a few more months\n",
      "a few more prices\n",
      "a few more words\n",
      "a few more hours\n",
      "a few more days\n",
      "A few more days\n",
      "a little more tweaks\n",
      "a few more tablets\n",
      "a few more gorillas\n",
      "a few more pieces\n",
      "a few more lottery tickets\n",
      "a few more eggs\n",
      "a few more vessels\n",
      "a few more pages\n",
      "a few more Volts\n",
      "a few more curves\n",
      "a few more examples\n",
      "a few more options\n",
      "a few more minutes\n",
      "a great many more men\n",
      "a few more times\n",
      "a few more details\n",
      "a few more slices\n",
      "a few more atoms\n",
      "a few more times\n",
      "a few more layers\n",
      "a few more handouts\n",
      "a few more babies\n",
      "a few more minutes\n",
      "a few more layers\n",
      "A few more years\n",
      "a few more examples\n",
      "A few more days\n",
      "a few more examples\n",
      "a few more parting shots\n",
      "a few more stores\n",
      "A few more repetitions\n",
      "a few more drinks\n",
      "a few more weeks\n",
      "a few more days\n",
      "A few more drops\n",
      "a few more days\n",
      "a few more minutes\n",
      "a few more coals\n",
      "a few more days\n",
      "a few more bits\n",
      "a few more states\n",
      "a few more thanks\n",
      "a few more days\n",
      "a few more tastes\n",
      "a few more times\n",
      "a few more techniques\n",
      "a few more people\n",
      "a few more pawns\n",
      "a few more steps\n",
      "a few more things\n",
      "a few more dog lives\n",
      "a few more days\n",
      "a few more words\n",
      "a few more days\n",
      "a few more steps\n",
      "A few more questions\n",
      "a few more definitions\n",
      "a few more things\n",
      "a few more days\n",
      "a few more widgets\n",
      "a few more concepts\n",
      "a few more Galileos\n",
      "a few more chairs\n",
      "a few more steps\n",
      "a few more questions\n",
      "a few more rounds\n",
      "a few more rounds\n",
      "a few more hours\n",
      "a few more days\n",
      "a few more days\n",
      "a few more spring collections\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more questions\n",
      "a few more hours\n",
      "a few more showers\n",
      "a few more moments\n",
      "a few more miles\n",
      "a few more mouths\n",
      "a few more days\n",
      "a few more agencies\n",
      "a few more people\n",
      "a few more minutes\n",
      "a few more years\n",
      "a few more newspapers\n",
      "a few more pictures\n",
      "a few more days\n",
      "a few more days\n",
      "a few more weeks\n",
      "A few more weeks\n",
      "a few more months\n",
      "a few more hours\n",
      "a few more minutes\n",
      "a few more hours\n",
      "a few more minutes\n",
      "a few more hours\n",
      "a few more minutes\n",
      "a few more times\n",
      "a few more days\n",
      "a few more minutes\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more metres\n",
      "a few more pennies\n",
      "a few more pennies\n",
      "a few more things\n",
      "a few more people\n",
      "a few more people\n",
      "a few more contributors\n",
      "a few more arguments\n",
      "a few more hours\n",
      "a few more notches\n",
      "a few more minutes\n",
      "a few more examples\n",
      "a few more hours\n",
      "a few more hours\n",
      "a few more winks\n",
      "a few more tests\n",
      "a few more days\n",
      "a few more hours\n",
      "A few more clicks\n",
      "A few more days'll\n",
      "a few more things\n",
      "a few more things\n",
      "A few more days\n",
      "a few more beers\n",
      "a few more cars\n",
      "A few more minutes\n",
      "a few more items\n",
      "A few more raids\n",
      "a few more questions\n",
      "a few more days\n",
      "a few more questions\n",
      "a few more days\n",
      "A few more hours\n",
      "a few more tests\n",
      "a few more surprises\n",
      "A few more feet\n",
      "A few more questions\n",
      "a few more stops\n",
      "a few more things\n",
      "a few more seconds\n",
      "a few more weeks\n",
      "a few more labs\n",
      "a few more crosses\n",
      "a few more crosses\n",
      "a few more prostitutes\n",
      "a few more tests\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more hours\n",
      "a few more people\n",
      "a few more questions\n",
      "a few more hours\n",
      "a few more areas\n",
      "a few more weeks\n",
      "A few more days\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more moments\n",
      "a few more days\n",
      "a few more days\n",
      "a few more ladies\n",
      "a few more moments\n",
      "a few more moments\n",
      "a few more moments\n",
      "a few more moments\n",
      "a few more cotton rolls\n",
      "a few more years\n",
      "a few more minutes\n",
      "A few more seconds\n",
      "a few more metres\n",
      "A few more seconds\n",
      "A few more seconds\n",
      "a few more interrogations\n",
      "A few more touches\n",
      "a few more beers\n",
      "a few more questions\n",
      "a few more races\n",
      "a few more races\n",
      "a few more races\n",
      "a few more races\n",
      "a few more minutes\n",
      "a few more months\n",
      "a few more months\n",
      "a few more days\n",
      "a few more days\n",
      "a few more calls\n",
      "a few more minutes\n",
      "a few more shows\n",
      "a few more clicks\n",
      "a few more details\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more people\n",
      "a few more seasons\n",
      "A few more minutes\n",
      "a few more things\n",
      "a few more things\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more times\n",
      "a few more minutes\n",
      "a few more days\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more seconds\n",
      "a few more days\n",
      "a few more days\n",
      "a few more victims\n",
      "a few more kinks\n",
      "a few more minutes\n",
      "a few more seconds\n",
      "a few more months\n",
      "a few more times\n",
      "a few more minutes\n",
      "a few more stories\n",
      "a few more customers\n",
      "a few more flowers\n",
      "a few more minutes\n",
      "a few more rounds\n",
      "a few more rounds\n",
      "a few more hours\n",
      "a few more maintenance people\n",
      "a few more hours\n",
      "a few more hours\n",
      "a few more days\n",
      "A few more minutes\n",
      "a little more places\n",
      "a few more times\n",
      "a few more days\n",
      "a few more adjustments\n",
      "a few more adjustments\n",
      "a few more hours\n",
      "a few more hours\n",
      "a few more minutes\n",
      "a few more minutes\n",
      "a few more glasses\n",
      "a few more glasses\n",
      "a few more minutes\n",
      "a good many more years\n",
      "a few more days\n",
      "a few more minutes\n",
      "a few more days\n",
      "a few more drinks\n",
      "a few more minutes\n",
      "a few more years\n",
      "a few more feet\n",
      "a few more miles\n",
      "a few more years\n",
      "a few more traumas\n",
      "a few more days\n",
      "a few more times\n",
      "A few more boards\n",
      "a few more times\n",
      "a few more demands\n",
      "a few more things\n",
      "a few more things\n",
      "a few more scenes\n",
      "a few more days\n",
      "a few more days\n",
      "A few more hours\n",
      "a few more games\n",
      "A few more seconds\n",
      "a few more days\n",
      "a few more steps\n",
      "a few more drinks\n",
      "a few more seconds\n",
      "a few more things\n",
      "a few more minutes\n",
      "a few more hours\n",
      "a few more hours\n",
      "a few more times\n",
      "a few more years\n",
      "a few more weeks\n",
      "a few more minutes\n",
      "a few more years\n",
      "a few more minutes\n",
      "A few more years\n",
      "a few more things\n",
      "a few more days\n",
      "a few more days\n",
      "a few more days\n",
      "a few more days\n",
      "a few more tests\n",
      "A few more miles\n",
      "a few more minutes\n",
      "a few more times\n",
      "a few more years\n",
      "a few more lifetimes\n",
      "a few more days\n",
      "a few more steps\n",
      "a few more days\n",
      "a few more details\n",
      "a few more months\n",
      "a few more days\n",
      "A few more layovers\n",
      "A few more layovers\n",
      "a few more tests\n",
      "a few more tests\n",
      "a few more chips\n",
      "a few more swords\n",
      "a few more hours\n",
      "a few more questions\n",
      "a few more things\n",
      "a few more things\n",
      "a few more pubs\n",
      "a few more star systems\n",
      "a few more days\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for aann in full_aann_data_indef_final:\n",
    "    if \"more\" in aann['construction']:\n",
    "        print(aann['construction'])\n",
    "        # i += 1\n",
    "    # if not detect_aann_advanced(aann['pattern']):\n",
    "        # i += 1\n",
    "        # print(aann['construction'], aann['pattern'])\n",
    "\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a623e7-853f-4f36-a1e3-e6f7feaf32da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diff_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m relevant_idxes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdiff_ids\u001b[49m:\n\u001b[1;32m      3\u001b[0m     edited \u001b[38;5;241m=\u001b[39m verify_and_edit(full_aann_data_corpuswise_indef_pruned[\u001b[38;5;28mid\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edited[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUMERAL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m & \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m edited[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m & \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diff_ids' is not defined"
     ]
    }
   ],
   "source": [
    "relevant_idxes = []\n",
    "for id in diff_ids:\n",
    "    edited = verify_and_edit(full_aann_data_corpuswise_indef_pruned[id])\n",
    "    if edited['NUMERAL'].replace(\" & \", \"\").replace(\"\\xa0\", \"\").strip() == '' or edited['ADJ'].replace(\" & \", \"\").replace(\"\\xa0\", \"\").strip() == '':\n",
    "        pass\n",
    "    else:\n",
    "        idxes = find_sentence(unicodedata.normalize(\"NFKD\", edited['sentence']), sents)\n",
    "        if len(idxes) == 0:\n",
    "            print(edited)\n",
    "        else:\n",
    "            edited['sentence_idx'] = idxes[0]\n",
    "            edited['source'] = 'babylm_sents'\n",
    "            full_aann_data_indef_final.append(edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6fb493a-5040-49b4-ae4a-7a5f547febe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2282"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_aann_data_indef_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0083109-965d-4217-bd99-8df80245c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DONE! NOW SEPARATE NUMERAL AND NON NUMERAL AND ENJOY LIFE -- REPEAT FOR THE/THEM\n",
    "## babylm-aanns-non-nums.csv full_aann_data_indef_final where numeral not in list\n",
    "## babylm-aanns-all.csv: full_aann_data_indef_final\n",
    "## babylm-aanns-nums.csv full_aann_data_indef_final where numeral in list\n",
    "\n",
    "for entry in full_aann_data_indef_final:\n",
    "    parsed = utils.parse_instance(entry)\n",
    "\n",
    "full_aann_data_indef_final_non_num = []\n",
    "full_aann_data_indef_final_num = []\n",
    "\n",
    "for entry in full_aann_data_indef_final:\n",
    "    if entry['NUMERAL'] in non_numerals:\n",
    "        full_aann_data_indef_final_non_num.append(entry)\n",
    "    else:\n",
    "        full_aann_data_indef_final_num.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2282, 1123, 1159)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_aann_data_indef_final), len(full_aann_data_indef_final_non_num), len(full_aann_data_indef_final_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b74f074-6a82-4ac9-9da1-a2035d7ed9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"../data/babylm-aanns/\"\n",
    "# cols = [\n",
    "#     \"source\",\n",
    "#     \"sentence\",\n",
    "#     \"sentence_idx\",\n",
    "#     \"construction\",\n",
    "#     \"pattern\",\n",
    "#     \"DT\",\n",
    "#     \"ADJ\",\n",
    "#     \"NUMERAL\",\n",
    "#     \"NOUN\",\n",
    "#     \"ADV\",\n",
    "# ]\n",
    "\n",
    "# df = pd.DataFrame(full_aann_data_indef_final)[cols]\n",
    "# df.reset_index()\n",
    "# df.to_csv(f\"{save_path}/aanns_indef_all.csv\", index=False)\n",
    "\n",
    "# df = pd.DataFrame(full_aann_data_indef_final_num)[cols]\n",
    "# df.reset_index()\n",
    "# df.to_csv(f\"{save_path}/aanns_indef_num.csv\", index=False)\n",
    "\n",
    "# df = pd.DataFrame(full_aann_data_indef_final_non_num)[cols]\n",
    "# df.reset_index()\n",
    "# df.to_csv(f\"{save_path}/aanns_indef_non_num.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33713"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_aann_data_corpuswise_pruned = []\n",
    "for entry in full_aann_data_corpuswise:\n",
    "    try:\n",
    "        pruned = prune_sentence(entry)\n",
    "        full_aann_data_corpuswise_pruned.append(pruned)\n",
    "    except:\n",
    "        pass\n",
    "    # idx = find_sentence(pruned['sentence'], sents)\n",
    "    # pruned['sentence_idx'] = idx\n",
    "    # full_aann_data_corpuswise_pruned.append(pruned)\n",
    "\n",
    "len(full_aann_data_corpuswise_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'million few a dollars'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_aann_data_indef_final[0]\n",
    "\n",
    "editors.naan(utils.parse_instance(full_aann_data_indef_final[0])).string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize(full_aann_data_indef_final[0]['sentence'])\n",
    "def check_construction_sentence(entry):\n",
    "    recombined = ' '.join(tokenize(entry['sentence']))\n",
    "    return entry['construction'] in recombined\n",
    "\n",
    "def check_construction_sentence_mass(entries):\n",
    "    for entry in entries:\n",
    "        recombined = ' '.join(tokenize(entry['sentence']))\n",
    "        if entry['construction'] not in recombined:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_construction_sentence_mass(full_aann_data_indef_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_aann_data_final = []\n",
    "for entry in full_aann_data:\n",
    "    edited = verify_and_edit(entry)\n",
    "    if edited['NUMERAL'] != '':\n",
    "        full_aann_data_final.append(edited)\n",
    "\n",
    "# get diff ids\n",
    "corpuswise_constructions = [c['construction'] for c in full_aann_data_corpuswise_pruned]\n",
    "sentencewise_constructions = [c['construction'] for c in full_aann_data]\n",
    "\n",
    "diff_ids = [i for i, x in enumerate(corpuswise_constructions) if x not in sentencewise_constructions]\n",
    "\n",
    "relevant_idxes = []\n",
    "for id in diff_ids:\n",
    "    edited = verify_and_edit(full_aann_data_corpuswise_pruned[id])\n",
    "    if edited['NUMERAL'].replace(\" & \", \"\").replace(\"\\xa0\", \"\").strip() == '' or edited['ADJ'].replace(\" & \", \"\").replace(\"\\xa0\", \"\").strip() == '':\n",
    "        pass\n",
    "    else:\n",
    "        idxes = find_sentence(unicodedata.normalize(\"NFKD\", edited['sentence']), sents)\n",
    "        if len(idxes) == 0:\n",
    "            print(edited)\n",
    "        else:\n",
    "            edited['sentence_idx'] = idxes[0]\n",
    "            edited['source'] = 'babylm_sents'\n",
    "            full_aann_data_final.append(edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in full_aann_data_final:\n",
    "    parsed = utils.parse_instance(entry)\n",
    "\n",
    "full_aann_data_final_non_num = []\n",
    "full_aann_data_final_num = []\n",
    "\n",
    "for entry in full_aann_data_final:\n",
    "    if entry['NUMERAL'] in non_numerals:\n",
    "        full_aann_data_final_non_num.append(entry)\n",
    "    else:\n",
    "        full_aann_data_final_num.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../data/babylm-aanns/\"\n",
    "cols = [\n",
    "    \"source\",\n",
    "    \"sentence\",\n",
    "    \"sentence_idx\",\n",
    "    \"construction\",\n",
    "    \"pattern\",\n",
    "    \"DT\",\n",
    "    \"ADJ\",\n",
    "    \"NUMERAL\",\n",
    "    \"NOUN\",\n",
    "    \"ADV\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(full_aann_data_final)[cols]\n",
    "df.reset_index()\n",
    "df.to_csv(f\"{save_path}/aanns_all_det_all.csv\", index=False)\n",
    "\n",
    "df = pd.DataFrame(full_aann_data_final_num)[cols]\n",
    "df.reset_index()\n",
    "df.to_csv(f\"{save_path}/aanns_all_det_num.csv\", index=False)\n",
    "\n",
    "df = pd.DataFrame(full_aann_data_final_non_num)[cols]\n",
    "df.reset_index()\n",
    "df.to_csv(f\"{save_path}/aanns_all_det_non_num.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06177edc-6384-466f-bc7e-61e4ba409473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_openbooks(path):\n",
    "    \"\"\"TODO: make read all\"\"\"\n",
    "    return [i.strip() for i in open(path, encoding=\"utf-8\").readlines() if i.strip() != \"\"]\n",
    "\n",
    "openbooks_sents = []\n",
    "train_files = glob.glob('/home/km55359/rawdata/books1/epubtxt/*.txt')\n",
    "for file in train_files:\n",
    "    openbooks_sents.extend(read_openbooks(file))\n",
    "openbooks_postags = read_openbooks(\"/home/km55359/rawdata/books1/postags.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36768629, 36768629)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(openbooks_sents), len(openbooks_postags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openbooks_aann_data = store_aanns(openbooks_sents, openbooks_postags, \"openbooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21638552-6b79-4fd8-8a9e-7723feb3f66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 4046)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDX=10\n",
    "# verify_and_edit(ultra_aann[IDX]), ultra_aann[IDX]\n",
    "numeral_aanns = []\n",
    "non_numeral_aanns = []\n",
    "for entry in full_aann_data_corpuswise_indef:\n",
    "    if entry['NUMERAL'] == '':\n",
    "        non_numeral_aanns.append(entry)\n",
    "    else:\n",
    "        numeral_aanns.append(entry)\n",
    "\n",
    "len(numeral_aanns), len(non_numeral_aanns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4ffb5c9-17b5-4d23-92b2-fe0e2d082f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 89)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpuswise_constructions = [c['construction'] for c in full_aann_data_corpuswise_indef]\n",
    "sentencewise_constructions = [c['construction'] for c in full_aann_data_indef]\n",
    "\n",
    "minus1 = [x for x in corpuswise_constructions if x not in sentencewise_constructions]\n",
    "minus2 = [x for x in sentencewise_constructions if x not in corpuswise_constructions]\n",
    "\n",
    "len(minus1), len(minus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4cb79895-c888-4cbb-8d53-846d305cf7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultra_aann = []\n",
    "for entry in full_aann_data_indef:\n",
    "    seq = entry['pattern']\n",
    "    searched_advanced = detect_aann_advanced(seq)\n",
    "    searched_basic = detect_aann_basic(seq)\n",
    "    searched_ultra = detect_aann_ultra(seq)\n",
    "    if searched_ultra and not searched_advanced:\n",
    "        ultra_aann.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c068e401-7739-4b1a-b057-28232d471494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DT': 'a',\n",
       "  'ADJ': 'round',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & blocks',\n",
       "  'ADV': '',\n",
       "  'sentence': 'and darted sharply south for a round dozen blocks, then went due east',\n",
       "  'sentence_idx': 217172,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a round dozen blocks'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & episodes',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Aside from said obsession he is a slight coward to Judy who he had developed a crush on as shown in a few dozen episodes alongside her husband Hugh.',\n",
       "  'sentence_idx': 238762,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen episodes'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & processes',\n",
       "  'ADV': '',\n",
       "  'sentence': 'And each oligodendrocyte will extend a few processes, maybe up to a few dozen processes each, towards the axons of neurons.',\n",
       "  'sentence_idx': 407686,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen processes'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & buildings',\n",
       "  'ADV': '',\n",
       "  'sentence': 'By 1965 fewer than a half dozen buildings had been rebuilt in the creek valley adjacent north of the city.',\n",
       "  'sentence_idx': 412972,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen buildings'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & men',\n",
       "  'ADV': '',\n",
       "  'sentence': 'surrounded by a half dozen men in armor one of whom attempted to seize',\n",
       "  'sentence_idx': 558281,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen men'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & years',\n",
       "  'ADV': '',\n",
       "  'sentence': 'a half dozen years back to a thoroughfare of great charm.',\n",
       "  'sentence_idx': 629791,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen years'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'round',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & reviews',\n",
       "  'ADV': '',\n",
       "  'sentence': 'were possible for me to write a round dozen reviews of this book, in as',\n",
       "  'sentence_idx': 860617,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a round dozen reviews'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & writers',\n",
       "  'ADV': '',\n",
       "  'sentence': \"Back in the late '60s, Nashville's songwriting community consisted of only a few dozen writers who received little credit for their achievements and whose royalty compensation was small, largely because of an antiquated copyright law.\",\n",
       "  'sentence_idx': 1415823,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen writers'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & oarsmen',\n",
       "  'ADV': '',\n",
       "  'sentence': 'river, driven by a half dozen oarsmen.',\n",
       "  'sentence_idx': 1528352,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen oarsmen'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & people',\n",
       "  'ADV': '',\n",
       "  'sentence': 'In 2006, a few dozen people lived in these four villages, and about 100 people lived in designated fish culture zones.',\n",
       "  'sentence_idx': 1551344,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen people'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & forces',\n",
       "  'ADV': '',\n",
       "  'sentence': \"There's at least a half dozen forces that could have trained our killer.\",\n",
       "  'sentence_idx': 1869616,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen forces'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & coaches',\n",
       "  'ADV': '',\n",
       "  'sentence': 'More than a half dozen coaches may assist the manager in running the team.',\n",
       "  'sentence_idx': 1956424,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen coaches'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & people',\n",
       "  'ADV': '',\n",
       "  'sentence': \"`` See here , Rilla , can you arrange that there wo n't be more than a few dozen people round ?\",\n",
       "  'sentence_idx': 2346036,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen people'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & people',\n",
       "  'ADV': '',\n",
       "  'sentence': 'even at its height, the membership never exceeded a few dozen people.',\n",
       "  'sentence_idx': 2448576,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen people'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & kilometers',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Between 21 and 24 January, the French traveled 500 kilometers, while the road being monitored by the air force, and finally stopped in the evening of 24 a few dozen kilometers from Gao.',\n",
       "  'sentence_idx': 2866094,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen kilometers'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & bricks',\n",
       "  'ADV': '',\n",
       "  'sentence': \"He said that a man who's gonna build a, build something, let's put it in a modern setting, the man who's gonna, a man and woman, a couple are gonna put an extension on their house, they don't just go down and buy a few dozen bricks, er, and a bag cement and start, they work out how much it's gonna cost them first of all.\",\n",
       "  'sentence_idx': 2900192,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen bricks'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'hard',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': \"Look,it's been a hard couple days for me.\",\n",
       "  'sentence_idx': 3507533,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a hard couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'hard',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & years',\n",
       "  'ADV': '',\n",
       "  'sentence': \"In fact,it's been a hard couple years.\",\n",
       "  'sentence_idx': 3507536,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a hard couple years'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'hard',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': \"Look, it's been a hard couple days for me.\",\n",
       "  'sentence_idx': 3511019,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a hard couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'hard',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & years',\n",
       "  'ADV': '',\n",
       "  'sentence': \"In fact, it's been a hard couple years.\",\n",
       "  'sentence_idx': 3511022,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a hard couple years'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'hard',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': \"Look, it's been a hard couple days for me.\",\n",
       "  'sentence_idx': 3514623,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a hard couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'hard',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & years',\n",
       "  'ADV': '',\n",
       "  'sentence': \"In fact, it's been a hard couple years.\",\n",
       "  'sentence_idx': 3514626,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a hard couple years'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & grains',\n",
       "  'ADV': '',\n",
       "  'sentence': 'It goes through a certain process  and suddenly from within this process where just a minute ago the seed  looked like something you could grind and make flour or bread from and now it looks bad.But from this bad looking seed,a stem comes out with a few dozen grains at its head.',\n",
       "  'sentence_idx': 3540911,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen grains'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & people',\n",
       "  'ADV': '',\n",
       "  'sentence': 'By comparison, during the same tornado outbreak, more than 2000 homes were completely destroyed, with another 7000 damaged, and yet only a few dozen people died in their homes.',\n",
       "  'sentence_idx': 3892220,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen people'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'rough',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': \"It's been a rough couple days.\",\n",
       "  'sentence_idx': 4084634,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a rough couple days'},\n",
       " {'DT': 'A',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & natives',\n",
       "  'ADV': '',\n",
       "  'sentence': 'A half dozen natives arose from the floor, sudden fear in their faces',\n",
       "  'sentence_idx': 4186753,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'A half dozen natives'},\n",
       " {'DT': 'an',\n",
       "  'ADJ': 'extra',\n",
       "  'NUMERAL': 'three',\n",
       "  'NOUN': 'couple & weeks',\n",
       "  'ADV': '',\n",
       "  'sentence': \"What I'm suggesting really, is let's get it on the agenda for budget review whenever the next meeting is, to be considered in depth, and if that gives an extra couple or three weeks for officers to write the report, fine, if it goes beyond the next policy and resources a week or two won't matter in the scheme of things, it's detailed consideration I'm looking for, rather than a fast fix in ten minutes at the next P and R.\",\n",
       "  'sentence_idx': 5259646,\n",
       "  'pattern': 'DT JJ NN CC CD NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'an extra couple or three weeks'},\n",
       " {'DT': 'A',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & people',\n",
       "  'ADV': '',\n",
       "  'sentence': 'A half dozen people died, and most of the city was destroyed.',\n",
       "  'sentence_idx': 5344154,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'A half dozen people'},\n",
       " {'DT': 'an',\n",
       "  'ADJ': 'extra',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & eggs',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Do you have an extra dozen eggs?',\n",
       "  'sentence_idx': 6365996,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'an extra dozen eggs'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & features',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Well, the reason is that, the number of rows in this matrix is much larger than the number of columns because you have a few features, maybe a few dozen features.',\n",
       "  'sentence_idx': 6761817,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen features'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'couple',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & volunteers',\n",
       "  'ADV': '',\n",
       "  'sentence': \"We've cultivated an awesome huge volunteer base a couple dozen volunteers, mostly women from local programming and open source communities.\",\n",
       "  'sentence_idx': 7143829,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a couple dozen volunteers'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & yards',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Only a few dozen yards away they could see the black forms of the',\n",
       "  'sentence_idx': 7165723,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen yards'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & places',\n",
       "  'ADV': '',\n",
       "  'sentence': 'In the warming after the last ice age, farming begins to take hold in a half dozen places around the globe, but by the fortunes of geography, no place in the ancient world has a better concentration of plants and animals',\n",
       "  'sentence_idx': 7611502,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen places'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'rough',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Just a rough couple days.',\n",
       "  'sentence_idx': 7681627,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a rough couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & times',\n",
       "  'ADV': '',\n",
       "  'sentence': 'I have told you, like, a half dozen times, we were kidnapped.',\n",
       "  'sentence_idx': 8239144,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a half dozen times'},\n",
       " {'DT': 'A',\n",
       "  'ADJ': 'half',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & bars',\n",
       "  'ADV': '',\n",
       "  'sentence': 'A half dozen bars, restaurants, and three massage parlors.',\n",
       "  'sentence_idx': 8311299,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'A half dozen bars'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'good',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & years',\n",
       "  'ADV': '',\n",
       "  'sentence': 'No, that was a good couple years before the Discovery.',\n",
       "  'sentence_idx': 8393158,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a good couple years'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'crazy',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': 'It was a crazy couple days, you know?',\n",
       "  'sentence_idx': 8408989,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a crazy couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'tumultuous',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & years',\n",
       "  'ADV': '',\n",
       "  'sentence': \"It's been a tumultuous couple years for you down in Miami from the Bullyinggate to missing on free agents like Mike Wallace to even having one of your players' wives rip on your quarterback Ryan Tannehill.\",\n",
       "  'sentence_idx': 8444125,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a tumultuous couple years'},\n",
       " {'DT': 'A',\n",
       "  'ADJ': 'couple',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & cattle',\n",
       "  'ADV': '',\n",
       "  'sentence': 'A couple dozen cattle should be a pushover.',\n",
       "  'sentence_idx': 8602712,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'A couple dozen cattle'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'rough',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & weeks',\n",
       "  'ADV': '',\n",
       "  'sentence': \"It's been a rough couple weeks for the Flyers.\",\n",
       "  'sentence_idx': 9063803,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a rough couple weeks'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'rough',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': \"It's been a rough couple days.\",\n",
       "  'sentence_idx': 9582887,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a rough couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'rough',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'couple & days',\n",
       "  'ADV': '',\n",
       "  'sentence': \"It's been a rough couple days.\",\n",
       "  'sentence_idx': 9583510,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a rough couple days'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'couple',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & rabbits',\n",
       "  'ADV': '',\n",
       "  'sentence': \"And we'd raise probably a couple dozen rabbits each year.\",\n",
       "  'sentence_idx': 9658556,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a couple dozen rabbits'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'couple',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & rabbits',\n",
       "  'ADV': '',\n",
       "  'sentence': \"And we'd raise probably a couple dozen rabbits each year.\",\n",
       "  'sentence_idx': 9659498,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a couple dozen rabbits'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'couple',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & rabbits',\n",
       "  'ADV': '',\n",
       "  'sentence': \"We'd raise probably a couple dozen rabbits each year.\",\n",
       "  'sentence_idx': 9660474,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a couple dozen rabbits'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'couple',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & drinks',\n",
       "  'ADV': '',\n",
       "  'sentence': 'And when that would happen, the only thing that would get me through it was a couple dozen drinks.',\n",
       "  'sentence_idx': 9730316,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a couple dozen drinks'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & slaves',\n",
       "  'ADV': '',\n",
       "  'sentence': 'I gathered a few dozen slaves.',\n",
       "  'sentence_idx': 10174105,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen slaves'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & people',\n",
       "  'ADV': '',\n",
       "  'sentence': 'We turned the Tribute Bureau upside down with a few dozen people, with two hundred people, forget the Slave Tribunal, we could go straight for the palace.',\n",
       "  'sentence_idx': 10174401,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen people'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & cruisers',\n",
       "  'ADV': '',\n",
       "  'sentence': 'In addition to the battleships, a few dozen cruisers were sunk.',\n",
       "  'sentence_idx': 11091648,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen cruisers'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & grams',\n",
       "  'ADV': '',\n",
       "  'sentence': 'Just a few dozen grams.',\n",
       "  'sentence_idx': 11125065,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen grams'},\n",
       " {'DT': 'a',\n",
       "  'ADJ': 'few',\n",
       "  'NUMERAL': '',\n",
       "  'NOUN': 'dozen & times',\n",
       "  'ADV': '',\n",
       "  'sentence': \"Yeah, I think the director's mentioned his name a few dozen times.\",\n",
       "  'sentence_idx': 11336583,\n",
       "  'pattern': 'DT JJ NN NNS',\n",
       "  'source': 'babylm_sents',\n",
       "  'construction': 'a few dozen times'}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_aann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0eb56583-12c6-4e71-99fe-2f4b8fd022b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': 'a',\n",
       " 'ADJ': 'few',\n",
       " 'NUMERAL': '',\n",
       " 'NOUN': 'dozen & episodes',\n",
       " 'ADV': '',\n",
       " 'sentence': 'Aside from said obsession he is a slight coward to Judy who he had developed a crush on as shown in a few dozen episodes alongside her husband Hugh.',\n",
       " 'sentence_idx': 238762,\n",
       " 'pattern': 'DT JJ NN NNS',\n",
       " 'source': 'babylm_sents',\n",
       " 'construction': 'a few dozen episodes'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_aann[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3dbba85-db51-4dff-b669-bbdf00e29e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': 'a',\n",
       " 'ADJ': 'few & more',\n",
       " 'NUMERAL': '',\n",
       " 'NOUN': 'minutes',\n",
       " 'ADV': '',\n",
       " 'sentence': 'Now we got a few more minutes here, so lets do something a little, snicker',\n",
       " 'sentence_idx': 772,\n",
       " 'pattern': 'DT JJ JJR NNS',\n",
       " 'source': 'babylm_sents',\n",
       " 'construction': 'a few more minutes'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store only sentence that has the construction\n",
    "full_aann_data_indef[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ad7b2-1384-4672-b192-662e2fb93e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
