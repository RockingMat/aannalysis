{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Manager().list()\n",
    "\n",
    "# tokenizer in parallel\n",
    "def tokenize(text):\n",
    "    tokens.extend(tokenizer.tokenize(text))\n",
    "\n",
    "# read file\n",
    "babylm = utils.read_file(\"/home/km55359/rawdata/babylm_data/babylm_100M/babylm_100M_train.txt\")\n",
    "\n",
    "# tokenize\n",
    "# Parallel(n_jobs=32)(delayed(tokenize)(text) for text in tqdm(babylm))\n",
    "\n",
    "def count_word_frequencies(sentence):\n",
    "    words = tokenizer.tokenize(sentence.lower())\n",
    "    return Counter(words)\n",
    "\n",
    "def merge_counters(counters):\n",
    "    result = Counter()\n",
    "    for counter in counters:\n",
    "        result.update(counter)\n",
    "    return result\n",
    "\n",
    "def count_word_frequencies_in_parallel(sentences):\n",
    "    # Use joblib's Parallel and delayed to parallelize the word frequency counting\n",
    "    counters = Parallel(n_jobs=-1)(delayed(count_word_frequencies)(sentence) for sentence in tqdm(sentences))\n",
    "    \n",
    "    # Merge individual counters into a single counter\n",
    "    word_frequencies = merge_counters(counters)\n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10175732/10175732 [01:17<00:00, 131364.95it/s]\n"
     ]
    }
   ],
   "source": [
    "word_counts = count_word_frequencies_in_parallel(babylm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/babylm-analysis/babylm-unigrams.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"word\", \"count\"])\n",
    "    for word, count in word_counts.most_common():\n",
    "        writer.writerow([word, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahowald_aanns = utils.read_csv_dict(\"../data/mahowald-aann/aanns_good.csv\")\n",
    "babylm_aanns = utils.read_csv_dict(\"../data/babylm-aanns/aanns_indef_all.csv\")\n",
    "\n",
    "aanns_in_babylm = [b['construction'] for b in babylm_aanns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12960"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mahowald_aanns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a mere three years\n",
      "a mere twenty years\n",
      "an extra five days\n",
      "a mere three years\n",
      "a mere twenty years\n",
      "an extra five days\n",
      "a mere three years\n",
      "a mere twenty years\n",
      "an extra five days\n",
      "\n",
      "Original: 12960; Unseen: 12951\n"
     ]
    }
   ],
   "source": [
    "# store mahowald aanns where the aans do not occur in babylm\n",
    "mahowald_unseen_aanns = []\n",
    "for aann in mahowald_aanns:\n",
    "    if aann[\"construction\"] not in aanns_in_babylm:\n",
    "        mahowald_unseen_aanns.append(aann)\n",
    "    else:\n",
    "        print(aann[\"construction\"])\n",
    "\n",
    "print(f\"\\nOriginal: {len(mahowald_aanns)}; Unseen: {len(mahowald_unseen_aanns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahowald_final = []\n",
    "for aann in mahowald_unseen_aanns:\n",
    "    if aann['ADJ'].lower() in word_counts and aann['NOUN'].lower() in word_counts and aann['NUMERAL'].lower() in word_counts:\n",
    "        mahowald_final.append(aann)\n",
    "    else:\n",
    "        print(aann['construction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.write_dict_list_to_csv(mahowald_final, \"../data/mahowald-aann/mahowald-aanns-unseen_good.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmisra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
