{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import utils\n",
    "\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager\n",
    "from tqdm import tqdm\n",
    "\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = utils.read_file(\"/home/km55359/rawdata/babylm_data/babylm_100M/sents/babylm_sents.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch into groups of 1k\n",
    "# batch_size = 6250\n",
    "# batches = []\n",
    "# batch = []\n",
    "# for line in mini_corpus:\n",
    "#     if batch_size < 0:\n",
    "#         batches.append(line)\n",
    "#     else:\n",
    "#         batch.append(line)\n",
    "#         if len(batch) == batch_size:\n",
    "#             batches.append(batch)\n",
    "#             batch = []\n",
    "# if batch:\n",
    "#     batches.append(batch)\n",
    "\n",
    "# def get_children_recursive(token):\n",
    "#     children = []\n",
    "#     for child in token.children:\n",
    "#         children.append({\n",
    "#             'text': child.text,\n",
    "#             'dep': child.dep_,\n",
    "#             'children': get_children_recursive(child)\n",
    "#         })\n",
    "#     return children\n",
    "\n",
    "def get_children_flatten(token, depth=0, dep=False):\n",
    "    children = []\n",
    "    for child in token.children:\n",
    "        if dep:\n",
    "            children.append((child.text.lower(), child.dep_, depth, child.i))\n",
    "        else:\n",
    "            children.append(child.text.lower())\n",
    "        children.extend(get_children_flatten(child, depth+1, dep))\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22528it [00:21, 1059.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/km55359/aannalysis/src/a few days.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcompling/home/km55359/aannalysis/src/a%20few%20days.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m docs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpipe(corpus, batch_size\u001b[39m=\u001b[39m\u001b[39m2048\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcompling/home/km55359/aannalysis/src/a%20few%20days.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m indef_articles_with_pl_nouns \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcompling/home/km55359/aannalysis/src/a%20few%20days.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m tqdm(docs):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcompling/home/km55359/aannalysis/src/a%20few%20days.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcompling/home/km55359/aannalysis/src/a%20few%20days.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mtag_ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNNS\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m token\u001b[39m.\u001b[39mtag_ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNNPS\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/language.py:1611\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[1;32m   1610\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1611\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[1;32m   1612\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:251\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:342\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/tokens/doc.pyx:811\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/site-packages/spacy/tokens/doc.pyx:127\u001b[0m, in \u001b[0;36mspacy.tokens.doc.SetEntsDefault.values\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/kmisra/lib/python3.11/enum.py:803\u001b[0m, in \u001b[0;36mEnumType.__members__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[39m    Return the number of members (no aliases)\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_member_names_)\n\u001b[0;32m--> 803\u001b[0m \u001b[39m@bltns\u001b[39m\u001b[39m.\u001b[39mproperty\n\u001b[1;32m    804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__members__\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m    805\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[39m    Returns a mapping of member name->value.\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \n\u001b[1;32m    808\u001b[0m \u001b[39m    This mapping lists all enum members, including aliases. Note that this\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[39m    is a read-only view of the internal mapping.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    811\u001b[0m     \u001b[39mreturn\u001b[39;00m MappingProxyType(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_member_map_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# mini_corpus = corpus[:100000]\n",
    "idx = 0\n",
    "docs = model.pipe(corpus, batch_size=2048)\n",
    "indef_articles_with_pl_nouns = []\n",
    "for doc in tqdm(docs):\n",
    "    for token in doc:\n",
    "        if token.tag_ == \"NNS\" or token.tag_ == \"NNPS\":\n",
    "            children = get_children_flatten(token, dep=True)\n",
    "            if len(children) >= 1:\n",
    "                # children_toks, children_deps = list(zip(*children))\n",
    "                # if \"a\" in children_toks or \"an\" in children_toks or \"another\" in children_toks:\n",
    "                #     found = True\n",
    "                #     indef_articles_with_pl_nouns.append((idx, token.text, children_toks, children_deps))\n",
    "                #     break\n",
    "                for child in children:\n",
    "                    # check for specific determiners and the fact that their indices are less than that of the noun:\n",
    "                    if child[0] in [\"a\", \"an\", \"another\"] and child[3] < token.i:\n",
    "                        found = True\n",
    "                        indef_articles_with_pl_nouns.append(\n",
    "                            (\n",
    "                                idx,\n",
    "                                token.text,\n",
    "                                token.i,\n",
    "                                child[0],\n",
    "                                child[1],\n",
    "                                child[2],\n",
    "                                child[3],\n",
    "                            )\n",
    "                        )\n",
    "                        break\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # for child in token.children:\n",
    "            # if child.text in [\"a\", \"an\", \"another\"]:\n",
    "            #     found = True\n",
    "            #     indef_articles_with_pl_nouns.append((idx, token.text, child.dep_, child.text))\n",
    "            #     break\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indef_articles_with_pl_nouns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/km55359/aannalysis/src/a few days.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcompling/home/km55359/aannalysis/src/a%20few%20days.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(indef_articles_with_pl_nouns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indef_articles_with_pl_nouns' is not defined"
     ]
    }
   ],
   "source": [
    "len(indef_articles_with_pl_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "indef_articles_with_pl_nouns\n",
    "\n",
    "# write to csv\n",
    "import csv\n",
    "with open(\"../data/babylm-analysis/indef_articles_with_pl_nouns.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"sentence_idx\", \"noun\", \"noun_idx\", \"article\", \"article_dep\", \"dep_depth\", \"article_idx\"])\n",
    "    for row in indef_articles_with_pl_nouns:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 293.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days ('a', 'few') ('det', 'amod')\n",
      "dollars ('hundred', 'a') ('nummod', 'quantmod')\n",
      "dollars ('hundred', 'a', 'few') ('nummod', 'quantmod', 'amod')\n",
      "dollars ('the', 'hundred', 'spent', 'i') ('det', 'nummod', 'relcl', 'nsubj')\n",
      "days ('five',) ('nummod',)\n",
      "weeks ('seven', 'of', 'writing', 'thesis') ('nummod', 'prep', 'pobj', 'compound')\n",
      "people ('five',) ('nummod',)\n",
      "dollars ('billion', 'twelve') ('nummod', 'compound')\n",
      "people ('five',) ('nummod',)\n",
      "eggs ('dozen', 'a') ('nummod', 'quantmod')\n",
      "eggs ('dozen', 'a') ('nummod', 'quantmod')\n",
      "days ('seven',) ('nummod',)\n",
      "minutes ('seven',) ('nummod',)\n",
      "days ('7',) ('nummod',)\n",
      "days ('7',) ('nummod',)\n",
      "days ('another', 'thousand') ('det', 'nummod')\n",
      "eggs ('dozen', 'a') ('nummod', 'quantmod')\n",
      "days ('a', 'beautiful', 'five') ('det', 'amod', 'nummod')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mini_corpus = [\n",
    "#     \"A few days should be enough for that task!\",\n",
    "#     \"A hundred dollars is a lot of money.\",\n",
    "#     \"A few hundred dollars is all we need for this mission.\",\n",
    "#     \"The hundred dollars I spent ended up being a lot of money.\",\n",
    "#     \"Five days is a long time to wait for a response.\",\n",
    "#     \"Seven weeks of thesis writing takes a toll on one's body.\",\n",
    "#     \"A year is a long time to wait.\",\n",
    "#     \"Five people is a not a huge number of attendees.\",\n",
    "#     \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "#     \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "#     \"Five people is a not a huge number of attendees.\",\n",
    "#     \"A dozen eggs is too many.\",\n",
    "#     \"A dozen eggs was too many.\",\n",
    "#     \"All it took was seven days.\",\n",
    "#     \"He was going to the bathroom, and all he took was seven minutes.\",\n",
    "#     \"7 days is what it took for him to get over it.\",\n",
    "#     \"He takes 7 days to get over it.\",\n",
    "#     \"That will take another thousand days.\",\n",
    "#     \"A dozen eggs was too many.\",\n",
    "#     \"The family spent a beautiful five days in austin.\"\n",
    "# ]\n",
    "# idx = 0\n",
    "# indef_articles_with_pl_nouns = []\n",
    "# for sentence in tqdm(mini_corpus):\n",
    "#     doc = model(sentence)\n",
    "#     found = False\n",
    "#     children = []\n",
    "#     for token in doc:\n",
    "#         if token.tag_ == \"NNS\" or token.tag_ == \"NNPS\":\n",
    "#             # children = get_children_flatten(token)\n",
    "#             # print(token.text, children)\n",
    "#             children = get_children_flatten(token, dep=True)\n",
    "#             # print(children)\n",
    "#             if len(children) >= 1:\n",
    "#                 children_toks, children_deps = list(zip(*children))\n",
    "#                 print(token.text, children_toks, children_deps)\n",
    "#             else:\n",
    "#                 pass\n",
    "\n",
    "#             # X = token\n",
    "#             # for child in token.children:\n",
    "#             #     if child.text in [\"a\", \"an\", \"another\"]:\n",
    "#             #         found = True\n",
    "#             #         indef_articles_with_pl_nouns.append((idx, token.text, child.dep_, child.text))\n",
    "#             #         break\n",
    "\n",
    "#     if found:\n",
    "#         print(sentence)\n",
    "#     idx+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmisra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
